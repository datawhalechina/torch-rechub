import{_ as a,c as t,o as i,ah as l}from"./chunks/framework.BwlcJEXh.js";const h=JSON.parse('{"title":"Utilities API Reference","description":"API documentation for Torch-RecHub utilities including data processing, vector retrieval, and multi-task learning tools","frontmatter":{"title":"Utilities API Reference","description":"API documentation for Torch-RecHub utilities including data processing, vector retrieval, and multi-task learning tools"},"headers":[],"relativePath":"manual/api-reference/utils.md","filePath":"en/manual/api-reference/utils.md"}'),r={name:"manual/api-reference/utils.md"};function o(s,e,n,d,c,u){return i(),t("div",null,[...e[0]||(e[0]=[l('<h1 id="utilities-api-reference" tabindex="-1">Utilities API Reference <a class="header-anchor" href="#utilities-api-reference" aria-label="Permalink to “Utilities API Reference”">​</a></h1><p>This document provides detailed API documentation for utility classes and functions in Torch-RecHub.</p><h2 id="data-processing-tools-data-py" tabindex="-1">Data Processing Tools (data.py) <a class="header-anchor" href="#data-processing-tools-data-py" aria-label="Permalink to “Data Processing Tools (data.py)”">​</a></h2><h3 id="dataset-classes" tabindex="-1">Dataset Classes <a class="header-anchor" href="#dataset-classes" aria-label="Permalink to “Dataset Classes”">​</a></h3><h4 id="torchdataset" tabindex="-1">TorchDataset <a class="header-anchor" href="#torchdataset" aria-label="Permalink to “TorchDataset”">​</a></h4><ul><li><strong>Introduction</strong>: Basic PyTorch dataset implementation for handling feature and label data.</li><li><strong>Parameters</strong>: <ul><li><code>x</code> (dict): Feature dictionary with feature names as keys and feature data as values</li><li><code>y</code> (array): Label data</li></ul></li></ul><h4 id="predictdataset" tabindex="-1">PredictDataset <a class="header-anchor" href="#predictdataset" aria-label="Permalink to “PredictDataset”">​</a></h4><ul><li><strong>Introduction</strong>: Dataset class for prediction stage containing only feature data.</li><li><strong>Parameters</strong>: <ul><li><code>x</code> (dict): Feature dictionary with feature names as keys and feature data as values</li></ul></li></ul><h4 id="matchdatagenerator" tabindex="-1">MatchDataGenerator <a class="header-anchor" href="#matchdatagenerator" aria-label="Permalink to “MatchDataGenerator”">​</a></h4><ul><li><strong>Introduction</strong>: Data generator for recall tasks to generate training and test data loaders.</li><li><strong>Main Methods</strong>: <ul><li><code>generate_dataloader(x_test_user, x_all_item, batch_size, num_workers=8)</code>: Generate train, test, and item data loaders</li><li><strong>Parameters</strong>: <ul><li><code>x_test_user</code> (dict): Test user features</li><li><code>x_all_item</code> (dict): All item features</li><li><code>batch_size</code> (int): Batch size</li><li><code>num_workers</code> (int): Number of worker processes for data loading</li></ul></li></ul></li></ul><h4 id="datagenerator" tabindex="-1">DataGenerator <a class="header-anchor" href="#datagenerator" aria-label="Permalink to “DataGenerator”">​</a></h4><ul><li><strong>Introduction</strong>: General-purpose data generator supporting dataset splitting and loading.</li><li><strong>Main Methods</strong>: <ul><li><code>generate_dataloader(x_val=None, y_val=None, x_test=None, y_test=None, split_ratio=None, batch_size=16, num_workers=0)</code>: Generate train, validation, and test data loaders</li><li><strong>Parameters</strong>: <ul><li><code>x_val</code>, <code>y_val</code>: Validation set features and labels</li><li><code>x_test</code>, <code>y_test</code>: Test set features and labels</li><li><code>split_ratio</code> (list): Split ratio for train, validation, and test sets</li><li><code>batch_size</code> (int): Batch size</li><li><code>num_workers</code> (int): Number of worker processes for data loading</li></ul></li></ul></li></ul><h3 id="utility-functions" tabindex="-1">Utility Functions <a class="header-anchor" href="#utility-functions" aria-label="Permalink to “Utility Functions”">​</a></h3><h4 id="get-auto-embedding-dim" tabindex="-1">get_auto_embedding_dim <a class="header-anchor" href="#get-auto-embedding-dim" aria-label="Permalink to “get_auto_embedding_dim”">​</a></h4><ul><li><strong>Introduction</strong>: Automatically calculate embedding dimension based on number of categories.</li><li><strong>Parameters</strong>: <ul><li><code>num_classes</code> (int): Number of categories</li></ul></li><li><strong>Returns</strong>: <ul><li>int: Embedding dimension, calculated as <code>[6 * (num_classes)^(1/4)]</code></li></ul></li></ul><h4 id="get-loss-func" tabindex="-1">get_loss_func <a class="header-anchor" href="#get-loss-func" aria-label="Permalink to “get_loss_func”">​</a></h4><ul><li><strong>Introduction</strong>: Get loss function.</li><li><strong>Parameters</strong>: <ul><li><code>task_type</code> (str): Task type, &quot;classification&quot; or &quot;regression&quot;</li></ul></li><li><strong>Returns</strong>: <ul><li>torch.nn.Module: Corresponding loss function</li></ul></li></ul><h4 id="get-metric-func" tabindex="-1">get_metric_func <a class="header-anchor" href="#get-metric-func" aria-label="Permalink to “get_metric_func”">​</a></h4><ul><li><strong>Introduction</strong>: Get evaluation metric function.</li><li><strong>Parameters</strong>: <ul><li><code>task_type</code> (str): Task type, &quot;classification&quot; or &quot;regression&quot;</li></ul></li><li><strong>Returns</strong>: <ul><li>function: Corresponding evaluation metric function</li></ul></li></ul><h4 id="generate-seq-feature" tabindex="-1">generate_seq_feature <a class="header-anchor" href="#generate-seq-feature" aria-label="Permalink to “generate_seq_feature”">​</a></h4><ul><li><strong>Introduction</strong>: Generate sequence features and negative samples.</li><li><strong>Parameters</strong>: <ul><li><code>data</code> (pd.DataFrame): Raw data</li><li><code>user_col</code> (str): User ID column name</li><li><code>item_col</code> (str): Item ID column name</li><li><code>time_col</code> (str): Timestamp column name</li><li><code>item_attribute_cols</code> (list): Item attribute columns for sequence feature generation</li><li><code>min_item</code> (int): Minimum number of items per user</li><li><code>shuffle</code> (bool): Whether to shuffle data</li><li><code>max_len</code> (int): Maximum sequence length</li></ul></li></ul><h2 id="recall-tools-match-py" tabindex="-1">Recall Tools (match.py) <a class="header-anchor" href="#recall-tools-match-py" aria-label="Permalink to “Recall Tools (match.py)”">​</a></h2><h3 id="data-processing-functions" tabindex="-1">Data Processing Functions <a class="header-anchor" href="#data-processing-functions" aria-label="Permalink to “Data Processing Functions”">​</a></h3><h4 id="gen-model-input" tabindex="-1">gen_model_input <a class="header-anchor" href="#gen-model-input" aria-label="Permalink to “gen_model_input”">​</a></h4><ul><li><strong>Introduction</strong>: Merge user and item features, handle sequence features.</li><li><strong>Parameters</strong>: <ul><li><code>df</code> (pd.DataFrame): Data with historical sequence features</li><li><code>user_profile</code> (pd.DataFrame): User feature data</li><li><code>user_col</code> (str): User column name</li><li><code>item_profile</code> (pd.DataFrame): Item feature data</li><li><code>item_col</code> (str): Item column name</li><li><code>seq_max_len</code> (int): Maximum sequence length</li><li><code>padding</code> (str): Padding method, &#39;pre&#39; or &#39;post&#39;</li><li><code>truncating</code> (str): Truncation method, &#39;pre&#39; or &#39;post&#39;</li></ul></li></ul><h4 id="negative-sample" tabindex="-1">negative_sample <a class="header-anchor" href="#negative-sample" aria-label="Permalink to “negative_sample”">​</a></h4><ul><li><strong>Introduction</strong>: Negative sampling method for recall models.</li><li><strong>Parameters</strong>: <ul><li><code>items_cnt_order</code> (dict): Item count dictionary sorted by count in descending order</li><li><code>ratio</code> (int): Negative sample ratio</li><li><code>method_id</code> (int): Sampling method ID <ul><li>0: Random sampling</li><li>1: Word2Vec-style popularity sampling</li><li>2: Log popularity sampling</li><li>3: Tencent RALM sampling</li></ul></li></ul></li></ul><h3 id="vector-retrieval-classes" tabindex="-1">Vector Retrieval Classes <a class="header-anchor" href="#vector-retrieval-classes" aria-label="Permalink to “Vector Retrieval Classes”">​</a></h3><h4 id="annoy" tabindex="-1">Annoy <a class="header-anchor" href="#annoy" aria-label="Permalink to “Annoy”">​</a></h4><ul><li><strong>Introduction</strong>: Vector retrieval tool based on Annoy library.</li><li><strong>Parameters</strong>: <ul><li><code>metric</code> (str): Distance metric</li><li><code>n_trees</code> (int): Number of trees</li><li><code>search_k</code> (int): Search parameter</li></ul></li><li><strong>Main Methods</strong>: <ul><li><code>fit(X)</code>: Build index</li><li><code>query(v, n)</code>: Query nearest neighbors</li></ul></li></ul><h4 id="milvus" tabindex="-1">Milvus <a class="header-anchor" href="#milvus" aria-label="Permalink to “Milvus”">​</a></h4><ul><li><strong>Introduction</strong>: Vector retrieval tool based on Milvus.</li><li><strong>Parameters</strong>: <ul><li><code>dim</code> (int): Vector dimension</li><li><code>host</code> (str): Milvus server address</li><li><code>port</code> (str): Milvus server port</li></ul></li><li><strong>Main Methods</strong>: <ul><li><code>fit(X)</code>: Build index</li><li><code>query(v, n)</code>: Query nearest neighbors</li></ul></li></ul><h2 id="multi-task-learning-tools-mtl-py" tabindex="-1">Multi-Task Learning Tools (mtl.py) <a class="header-anchor" href="#multi-task-learning-tools-mtl-py" aria-label="Permalink to “Multi-Task Learning Tools (mtl.py)”">​</a></h2><h3 id="utility-functions-1" tabindex="-1">Utility Functions <a class="header-anchor" href="#utility-functions-1" aria-label="Permalink to “Utility Functions”">​</a></h3><h4 id="shared-task-layers" tabindex="-1">shared_task_layers <a class="header-anchor" href="#shared-task-layers" aria-label="Permalink to “shared_task_layers”">​</a></h4><ul><li><strong>Introduction</strong>: Get shared and task-specific layer parameters from multi-task models.</li><li><strong>Parameters</strong>: <ul><li><code>model</code> (torch.nn.Module): Multi-task model supporting MMOE, SharedBottom, PLE, AITM</li></ul></li><li><strong>Returns</strong>: <ul><li>list: Shared layer parameters</li><li>list: Task-specific layer parameters</li></ul></li></ul><h3 id="optimizer-classes" tabindex="-1">Optimizer Classes <a class="header-anchor" href="#optimizer-classes" aria-label="Permalink to “Optimizer Classes”">​</a></h3><h4 id="metabalance" tabindex="-1">MetaBalance <a class="header-anchor" href="#metabalance" aria-label="Permalink to “MetaBalance”">​</a></h4><ul><li><strong>Introduction</strong>: MetaBalance optimizer for balancing gradients across tasks in multi-task learning.</li><li><strong>Parameters</strong>: <ul><li><code>parameters</code> (list): Model parameters</li><li><code>relax_factor</code> (float): Gradient scaling relaxation factor, default 0.7</li><li><code>beta</code> (float): Moving average coefficient, default 0.9</li></ul></li><li><strong>Main Methods</strong>: <ul><li><code>step(losses)</code>: Perform optimization step and update parameters</li></ul></li></ul><h3 id="gradient-processing-functions" tabindex="-1">Gradient Processing Functions <a class="header-anchor" href="#gradient-processing-functions" aria-label="Permalink to “Gradient Processing Functions”">​</a></h3><h4 id="gradnorm" tabindex="-1">gradnorm <a class="header-anchor" href="#gradnorm" aria-label="Permalink to “gradnorm”">​</a></h4><ul><li><strong>Introduction</strong>: Implement GradNorm algorithm for dynamic task weight adjustment in multi-task learning.</li><li><strong>Parameters</strong>: <ul><li><code>loss_list</code> (list): Loss list for each task</li><li><code>loss_weight</code> (list): Task weight list</li><li><code>share_layer</code> (torch.nn.Parameter): Shared layer parameters</li><li><code>initial_task_loss</code> (list): Initial task loss list</li><li><code>alpha</code> (float): GradNorm algorithm hyperparameter</li></ul></li></ul>',42)])])}const g=a(r,[["render",o]]);export{h as __pageData,g as default};
