import{_ as a,c as t,o,aj as r}from"./chunks/framework.CFr_S-Bc.js";const h=JSON.parse('{"title":"Basic Components API Reference","description":"Detailed API documentation for basic components including feature processing and data transformation","frontmatter":{"title":"Basic Components API Reference","description":"Detailed API documentation for basic components including feature processing and data transformation"},"headers":[],"relativePath":"manual/api-reference/basic.md","filePath":"en/manual/api-reference/basic.md"}'),n={name:"manual/api-reference/basic.md"};function i(l,e,s,d,c,u){return o(),t("div",null,[...e[0]||(e[0]=[r('<h1 id="basic-components-api-reference" tabindex="-1">Basic Components API Reference <a class="header-anchor" href="#basic-components-api-reference" aria-label="Permalink to “Basic Components API Reference”">​</a></h1><p>This document provides detailed documentation for basic components in Torch-RecHub, including feature processing, data transformation, and other fundamental functionalities.</p><h2 id="feature-processing" tabindex="-1">Feature Processing <a class="header-anchor" href="#feature-processing" aria-label="Permalink to “Feature Processing”">​</a></h2><h3 id="feature-columns" tabindex="-1">Feature Columns <a class="header-anchor" href="#feature-columns" aria-label="Permalink to “Feature Columns”">​</a></h3><h4 id="densefeature" tabindex="-1">DenseFeature <a class="header-anchor" href="#densefeature" aria-label="Permalink to “DenseFeature”">​</a></h4><ul><li><strong>Introduction</strong>: Process continuous numerical features.</li><li><strong>Parameters</strong>: <ul><li><code>name</code> (str): Feature name</li><li><code>dimension</code> (int): Feature dimension</li><li><code>dtype</code> (str): Data type, default &#39;float32&#39;</li></ul></li></ul><h4 id="sparsefeature" tabindex="-1">SparseFeature <a class="header-anchor" href="#sparsefeature" aria-label="Permalink to “SparseFeature”">​</a></h4><ul><li><strong>Introduction</strong>: Process discrete categorical features.</li><li><strong>Parameters</strong>: <ul><li><code>name</code> (str): Feature name</li><li><code>vocabulary_size</code> (int): Size of category vocabulary</li><li><code>embedding_dim</code> (int): Embedding vector dimension</li><li><code>dtype</code> (str): Data type, default &#39;int32&#39;</li><li><code>embedding_name</code> (str): Embedding layer name, default None</li></ul></li></ul><h4 id="varlensparsefeature" tabindex="-1">VarLenSparseFeature <a class="header-anchor" href="#varlensparsefeature" aria-label="Permalink to “VarLenSparseFeature”">​</a></h4><ul><li><strong>Introduction</strong>: Process variable-length discrete features.</li><li><strong>Parameters</strong>: <ul><li><code>name</code> (str): Feature name</li><li><code>vocabulary_size</code> (int): Size of category vocabulary</li><li><code>embedding_dim</code> (int): Embedding vector dimension</li><li><code>maxlen</code> (int): Maximum sequence length</li><li><code>dtype</code> (str): Data type, default &#39;int32&#39;</li><li><code>embedding_name</code> (str): Embedding layer name, default None</li><li><code>combiner</code> (str): Sequence pooling method, options: &#39;sum&#39;, &#39;mean&#39;, &#39;max&#39;, default &#39;mean&#39;</li></ul></li></ul><h2 id="data-transformation" tabindex="-1">Data Transformation <a class="header-anchor" href="#data-transformation" aria-label="Permalink to “Data Transformation”">​</a></h2><h3 id="data-preprocessing" tabindex="-1">Data Preprocessing <a class="header-anchor" href="#data-preprocessing" aria-label="Permalink to “Data Preprocessing”">​</a></h3><h4 id="minmaxscaler" tabindex="-1">MinMaxScaler <a class="header-anchor" href="#minmaxscaler" aria-label="Permalink to “MinMaxScaler”">​</a></h4><ul><li><strong>Introduction</strong>: Normalize numerical features.</li><li><strong>Parameters</strong>: <ul><li><code>feature_range</code> (tuple): Normalization range, default (0, 1)</li></ul></li></ul><h4 id="standardscaler" tabindex="-1">StandardScaler <a class="header-anchor" href="#standardscaler" aria-label="Permalink to “StandardScaler”">​</a></h4><ul><li><strong>Introduction</strong>: Standardize numerical features.</li><li><strong>Parameters</strong>: <ul><li><code>with_mean</code> (bool): Whether to remove mean, default True</li><li><code>with_std</code> (bool): Whether to scale by standard deviation, default True</li></ul></li></ul><h4 id="labelencoder" tabindex="-1">LabelEncoder <a class="header-anchor" href="#labelencoder" aria-label="Permalink to “LabelEncoder”">​</a></h4><ul><li><strong>Introduction</strong>: Encode categorical features.</li><li><strong>Methods</strong>: <ul><li><code>fit(values)</code>: Fit the encoder</li><li><code>transform(values)</code>: Transform data</li><li><code>fit_transform(values)</code>: Fit and transform</li></ul></li></ul><h3 id="data-format-conversion" tabindex="-1">Data Format Conversion <a class="header-anchor" href="#data-format-conversion" aria-label="Permalink to “Data Format Conversion”">​</a></h3><h4 id="pandas-to-torch" tabindex="-1">pandas_to_torch <a class="header-anchor" href="#pandas-to-torch" aria-label="Permalink to “pandas_to_torch”">​</a></h4><ul><li><strong>Introduction</strong>: Convert Pandas data to PyTorch tensors.</li><li><strong>Parameters</strong>: <ul><li><code>df</code> (pd.DataFrame): Input DataFrame</li><li><code>dense_cols</code> (list): List of continuous feature column names</li><li><code>sparse_cols</code> (list): List of discrete feature column names</li><li><code>device</code> (str): Device type, &#39;cpu&#39; or &#39;cuda&#39;</li></ul></li></ul><h4 id="numpy-to-torch" tabindex="-1">numpy_to_torch <a class="header-anchor" href="#numpy-to-torch" aria-label="Permalink to “numpy_to_torch”">​</a></h4><ul><li><strong>Introduction</strong>: Convert NumPy arrays to PyTorch tensors.</li><li><strong>Parameters</strong>: <ul><li><code>arrays</code> (list): List of NumPy arrays</li><li><code>device</code> (str): Device type, &#39;cpu&#39; or &#39;cuda&#39;</li></ul></li></ul><h2 id="model-components" tabindex="-1">Model Components <a class="header-anchor" href="#model-components" aria-label="Permalink to “Model Components”">​</a></h2><h3 id="activation-functions" tabindex="-1">Activation Functions <a class="header-anchor" href="#activation-functions" aria-label="Permalink to “Activation Functions”">​</a></h3><h4 id="dice" tabindex="-1">Dice <a class="header-anchor" href="#dice" aria-label="Permalink to “Dice”">​</a></h4><ul><li><strong>Introduction</strong>: Dice activation function, proposed in Deep Interest Network (DIN).</li><li><strong>Parameters</strong>: <ul><li><code>epsilon</code> (float): Smoothing parameter, default 1e-3</li><li><code>device</code> (str): Device type, default &#39;cpu&#39;</li></ul></li></ul><h3 id="attention-mechanisms" tabindex="-1">Attention Mechanisms <a class="header-anchor" href="#attention-mechanisms" aria-label="Permalink to “Attention Mechanisms”">​</a></h3><h4 id="scaleddotproductattention" tabindex="-1">ScaledDotProductAttention <a class="header-anchor" href="#scaleddotproductattention" aria-label="Permalink to “ScaledDotProductAttention”">​</a></h4><ul><li><strong>Introduction</strong>: Scaled dot-product attention mechanism.</li><li><strong>Parameters</strong>: <ul><li><code>temperature</code> (float): Temperature parameter for scaling</li><li><code>attn_dropout</code> (float): Attention dropout rate</li></ul></li></ul><h4 id="multiheadattention" tabindex="-1">MultiHeadAttention <a class="header-anchor" href="#multiheadattention" aria-label="Permalink to “MultiHeadAttention”">​</a></h4><ul><li><strong>Introduction</strong>: Multi-head attention mechanism.</li><li><strong>Parameters</strong>: <ul><li><code>d_model</code> (int): Model dimension</li><li><code>n_heads</code> (int): Number of attention heads</li><li><code>d_k</code> (int): Key vector dimension</li><li><code>d_v</code> (int): Value vector dimension</li><li><code>dropout</code> (float): Dropout rate</li></ul></li></ul>',32)])])}const f=a(n,[["render",i]]);export{h as __pageData,f as default};
