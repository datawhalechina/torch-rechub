<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Matching Models Training Guide | torch-rechub</title>
    <meta name="description" content="Comprehensive guide on loss functions, similarity metrics, and temperature scaling for matching models">
    <meta name="generator" content="VitePress v2.0.0-alpha.15">
    <link rel="preload stylesheet" href="/torch-rechub/assets/style.S8AY_U8R.css" as="style">
    <link rel="preload stylesheet" href="/torch-rechub/vp-icons.css" as="style">
    
    <script type="module" src="/torch-rechub/assets/app.C3gC3tXb.js"></script>
    <link rel="preload" href="/torch-rechub/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/torch-rechub/assets/chunks/theme.DCnJhaFE.js">
    <link rel="modulepreload" href="/torch-rechub/assets/chunks/framework.B-q_H0pu.js">
    <link rel="modulepreload" href="/torch-rechub/assets/blog_match.md.D2h5Vg4w.lean.js">
    <link rel="icon" href="/torch-rechub/favicon.ico">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-1df9f90f><!--[--><!--]--><!--[--><span tabindex="-1" data-v-331ec75c></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-331ec75c>Skip to content</a><!--]--><!----><header class="VPNav" data-v-1df9f90f data-v-da52a441><div class="VPNavBar" data-v-da52a441 data-v-70946a35><div class="wrapper" data-v-70946a35><div class="container" data-v-70946a35><div class="title" data-v-70946a35><div class="VPNavBarTitle has-sidebar" data-v-70946a35 data-v-1e38c6bc><a class="title" href="/torch-rechub/" data-v-1e38c6bc><!--[--><!--]--><!--[--><img class="VPImage logo" src="/torch-rechub/img/logo.png" alt data-v-8426fc1a><!--]--><span data-v-1e38c6bc>torch-rechub</span><!--[--><!--]--></a></div></div><div class="content" data-v-70946a35><div class="content-body" data-v-70946a35><!--[--><!--]--><div class="VPNavBarSearch search" data-v-70946a35><!----></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-70946a35 data-v-39714824><span id="main-nav-aria-label" class="visually-hidden" data-v-39714824> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/torch-rechub/" tabindex="0" data-v-39714824 data-v-52a1d768><!--[--><span data-v-52a1d768>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/torch-rechub/introduction.html" tabindex="0" data-v-39714824 data-v-52a1d768><!--[--><span data-v-52a1d768>Introduction</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/torch-rechub/manual/installation.html" tabindex="0" data-v-39714824 data-v-52a1d768><!--[--><span data-v-52a1d768>Documentation</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/torch-rechub/manual/api-reference/basic.html" tabindex="0" data-v-39714824 data-v-52a1d768><!--[--><span data-v-52a1d768>API</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink active" href="/torch-rechub/blog/match.html" tabindex="0" data-v-39714824 data-v-52a1d768><!--[--><span data-v-52a1d768>Blog</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/torch-rechub/contributing.html" tabindex="0" data-v-39714824 data-v-52a1d768><!--[--><span data-v-52a1d768>Contributing</span><!--]--></a><!--]--><!--]--></nav><div class="VPFlyout VPNavBarTranslations translations" data-v-70946a35 data-v-4c1766e2 data-v-42cb505d><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="Change language" data-v-42cb505d><span class="text" data-v-42cb505d><span class="vpi-languages option-icon" data-v-42cb505d></span><!----><span class="vpi-chevron-down text-icon" data-v-42cb505d></span></span></button><div class="menu" data-v-42cb505d><div class="VPMenu" data-v-42cb505d data-v-25a6cce8><!----><!--[--><!--[--><div class="items" data-v-4c1766e2><p class="title" data-v-4c1766e2>English</p><!--[--><div class="VPMenuLink" data-v-4c1766e2 data-v-faf5b206><a class="VPLink link" href="/torch-rechub/zh/blog/match.html" lang="zh-CN" data-v-faf5b206><!--[--><span data-v-faf5b206>ä¸­æ–‡</span><!--]--></a></div><!--]--></div><!--]--><!--]--></div></div></div><div class="VPNavBarAppearance appearance" data-v-70946a35 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-70946a35 data-v-0394ad82 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/datawhalechina/torch-rechub" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-70946a35 data-v-bf2fac68 data-v-42cb505d><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-42cb505d><span class="vpi-more-horizontal icon" data-v-42cb505d></span></button><div class="menu" data-v-42cb505d><div class="VPMenu" data-v-42cb505d data-v-25a6cce8><!----><!--[--><!--[--><div class="group translations" data-v-bf2fac68><p class="trans-title" data-v-bf2fac68>English</p><!--[--><div class="VPMenuLink" data-v-bf2fac68 data-v-faf5b206><a class="VPLink link" href="/torch-rechub/zh/blog/match.html" lang="zh-CN" data-v-faf5b206><!--[--><span data-v-faf5b206>ä¸­æ–‡</span><!--]--></a></div><!--]--></div><div class="group" data-v-bf2fac68><div class="item appearance" data-v-bf2fac68><p class="label" data-v-bf2fac68>Appearance</p><div class="appearance-action" data-v-bf2fac68><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bf2fac68 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bf2fac68><div class="item social-links" data-v-bf2fac68><div class="VPSocialLinks social-links-list" data-v-bf2fac68 data-v-d07f11e6><!--[--><a class="VPSocialLink no-icon" href="https://github.com/datawhalechina/torch-rechub" aria-label="github" target="_blank" rel="me noopener" data-v-d07f11e6 data-v-591a6b30><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-70946a35 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-70946a35><div class="divider-line" data-v-70946a35></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-1df9f90f data-v-db738f89><div class="container" data-v-db738f89><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-db738f89><span class="vpi-align-left menu-icon" data-v-db738f89></span><span class="menu-text" data-v-db738f89>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-db738f89 data-v-0bf0e06f><button data-v-0bf0e06f>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-1df9f90f data-v-af661f50><div class="curtain" data-v-af661f50></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-af661f50><span class="visually-hidden" id="sidebar-aria-label" data-v-af661f50> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-8d50c081><section class="VPSidebarItem level-0 has-active" data-v-8d50c081 data-v-d81de50c><div class="item" role="button" tabindex="0" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><h2 class="text" data-v-d81de50c>Blog</h2><!----></div><div class="items" data-v-d81de50c><!--[--><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/torch-rechub/blog/match.html" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Matching Training Guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/torch-rechub/blog/rank.html" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>Ranking Training Guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/torch-rechub/blog/hstu_reproduction.html" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>HSTU Reproduction</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-d81de50c data-v-d81de50c><div class="item" data-v-d81de50c><div class="indicator" data-v-d81de50c></div><a class="VPLink link link" href="/torch-rechub/blog/hllm_reproduction.html" data-v-d81de50c><!--[--><p class="text" data-v-d81de50c>HLLM Reproduction</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-1df9f90f data-v-c87f25bf><div class="VPDoc has-sidebar has-aside" data-v-c87f25bf data-v-7011f0d8><!--[--><!--]--><div class="container" data-v-7011f0d8><div class="aside" data-v-7011f0d8><div class="aside-curtain" data-v-7011f0d8></div><div class="aside-container" data-v-7011f0d8><div class="aside-content" data-v-7011f0d8><div class="VPDocAside" data-v-7011f0d8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-60d5052e><div class="content" data-v-60d5052e><div class="outline-marker" data-v-60d5052e></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-60d5052e>On this page</div><ul class="VPDocOutlineItem root" data-v-60d5052e data-v-1ce71065><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-7011f0d8><div class="content-container" data-v-7011f0d8><!--[--><!--]--><main class="main" data-v-7011f0d8><div style="position:relative;" class="vp-doc _torch-rechub_blog_match" data-v-7011f0d8><div><h2 id="i-understanding-different-loss-functions-â€”-3-training-methods" tabindex="-1">I. Understanding Different Loss Functions â€” 3 Training Methods <a class="header-anchor" href="#i-understanding-different-loss-functions-â€”-3-training-methods" aria-label="Permalink to â€œI. Understanding Different Loss Functions â€” 3 Training Methodsâ€">â€‹</a></h2><p>In recall tasks, there are generally three training methods: point-wise, pair-wise, and list-wise. In RecHub, we use the <em><strong>mode</strong></em> parameter to specify the training method, with each method corresponding to a different loss function.</p><h4 id="_1-1-point-wise-mode-0" tabindex="-1">1.1 Point-wise (mode = 0) <a class="header-anchor" href="#_1-1-point-wise-mode-0" aria-label="Permalink to â€œ1.1 Point-wise (mode = 0)â€">â€‹</a></h4><blockquote><p>ğŸ¥°<strong>Core Idea: Treat recall as binary classification.</strong></p></blockquote><p>For a recall model, the input is a tuple &lt;User, Item&gt;, and the output is $P(User, Item)$, representing the user&#39;s interest level in the item.</p><p>Training objective: For positive samples, the output should be as close to 1 as possible; for negative samples, as close to 0 as possible.</p><p>The most commonly used loss function is BCELoss (Binary Cross Entropy Loss).</p><h4 id="_1-2-pair-wise-mode-1" tabindex="-1">1.2 Pair-wise (mode = 1) <a class="header-anchor" href="#_1-2-pair-wise-mode-1" aria-label="Permalink to â€œ1.2 Pair-wise (mode = 1)â€">â€‹</a></h4><blockquote><p>ğŸ˜<strong>Core Idea: A user&#39;s interest in positive samples should be higher than in negative samples.</strong></p></blockquote><p>For a recall model, the input is a triple &lt;User, ItemPositive, ItemNegative&gt;, outputting interest scores $P(User, ItemPositive)$ and $P(User, ItemNegative)$, representing the user&#39;s interest scores for positive and negative item samples.</p><p>Training objective: The interest score for positive samples should be higher than that for negative samples.</p><p>The framework uses BPRLoss (Bayes Personalized Ranking Loss). Here&#39;s the loss formula (for more details, see <a href="https://www.cnblogs.com/pinard/p/9128682.html" title="here" target="_blank" rel="noreferrer">here</a> - note that there are slight differences between the linked content and the formula below, but the core idea remains the same):</p><p>$$ Loss=\frac{1}{N}\sum^N\ _{i=1}-log(sigmoid(pos_score - neg_score)) $$</p><hr><h4 id="_1-3-list-wise-mode-2" tabindex="-1">1.3 List-wise (mode = 2) <a class="header-anchor" href="#_1-3-list-wise-mode-2" aria-label="Permalink to â€œ1.3 List-wise (mode = 2)â€">â€‹</a></h4><blockquote><p>ğŸ˜‡<strong>Core Idea: A user&#39;s interest in positive samples should be higher than in negative samples.</strong></p></blockquote><p>Wait, isn&#39;t this the same as Pair-wise?</p><p>Yes! The core idea of List-wise training is the same as Pair-wise, but the implementation differs.</p><p>For a recall model, the input is an N+2 tuple $&lt;User, ItemPositive, ItemNeg_1, ... , ItemNeg_N&gt;$, outputting interest scores for 1 positive sample and N negative samples.</p><p>Training objective: The interest score for the positive sample should be higher than all negative samples.</p><p>The framework uses $torch.nn.CrossEntropyLoss$, applying Softmax to the outputs.</p><blockquote><p>PS: This List-wise approach can be easily confused with List-wise in Ranking. Although they share the same name, List-wise in ranking considers the order relationship between samples. For example, ranking uses order-sensitive metrics like MAP and NDCG for evaluation, while List-wise in Matching doesn&#39;t consider order.</p></blockquote><h2 id="ii-how-far-apart-are-two-vectors-â€”-3-similarity-metrics" tabindex="-1">II. How Far Apart Are Two Vectors? â€” 3 Similarity Metrics <a class="header-anchor" href="#ii-how-far-apart-are-two-vectors-â€”-3-similarity-metrics" aria-label="Permalink to â€œII. How Far Apart Are Two Vectors? â€” 3 Similarity Metricsâ€">â€‹</a></h2><blockquote><p>ğŸ¤”Given a user vector and an item vector, how do we measure their similarity?</p></blockquote><p>Let&#39;s first define user vector $user \in \mathcal R^D$ and item vector $item\in \mathcal R^D$, where D represents their dimension.</p><h3 id="_2-1-cosine" tabindex="-1">2.1 Cosine <a class="header-anchor" href="#_2-1-cosine" aria-label="Permalink to â€œ2.1 Cosineâ€">â€‹</a></h3><p>From middle school math:</p><p>$$ cos(a,b)=\frac{&lt;a,b&gt;}{|a|*|b|} $$</p><p>This represents the angle between two vectors, outputting a real number between [-1, 1]. We can use this as a similarity measure: the smaller the angle between vectors, the more similar they are.</p><p>In all two-tower models in RecHub, cosine similarity is used during the training phase.</p><h3 id="_2-2-dot-product" tabindex="-1">2.2 Dot Product <a class="header-anchor" href="#_2-2-dot-product" aria-label="Permalink to â€œ2.2 Dot Productâ€">â€‹</a></h3><p>This is the inner product of vectors, denoted as $&lt;a,b&gt;$ for vectors a and b.</p><p>A simple insight: <strong>If we L2 normalize vectors a and b, i.e., $\tilde{a}=\frac{a}{|a|}\ ,\tilde{b}=\frac{b}{|b|}$, then computing their dot product is equivalent to $cos(a,b)$</strong>. (This is straightforward, so we&#39;ll skip the proof)</p><p>In fact, this is exactly how all two-tower models in RecHub work: first computing User Embedding and Item Embedding, then applying L2 Norm to each, and finally computing their dot product to get cosine similarity. This approach improves model validation and inference speed.</p><h3 id="_2-3-euclidean-distance" tabindex="-1">2.3 Euclidean Distance <a class="header-anchor" href="#_2-3-euclidean-distance" aria-label="Permalink to â€œ2.3 Euclidean Distanceâ€">â€‹</a></h3><p>Euclidean distance is what we commonly understand as &quot;distance&quot; in everyday life.</p><blockquote><p>ğŸ™‹<strong>For L2 normalized vectors a and b, maximizing their cosine similarity is equivalent to minimizing their Euclidean distance</strong></p></blockquote><p>Why? See the formula below:</p><p>$$ \begin{align*} EuclidianDistance(a,b)^2 &amp;= \sum_{i=1}^N(a_i-b_i)^2 \ &amp;= \sum_{i=1}^Na_i^2+\sum_{i=1}^Nb_i^2-\sum_{i=1}^N2<em>a_i</em>b_i\ &amp;= 2-2*\sum_{i=1}^Na_i<em>b_i \ &amp;= 2</em>(1-cos(a,b)) \end{align*} $$</p><p>Two points to explain:</p><ol><li>From second line to third line, $\sum\ _{i=1}^N a_i^2=1$. Why? Because a is L2 normalized. Same for b.</li><li>From third line to fourth line, $\sum_{i=1}^Na_i*b_i$ is the dot product of vectors a and b; since they&#39;re L2 normalized, this equals cos.</li></ol><p>In RecHub, we use Annoy&#39;s Euclidean distance during the validation phase.</p><blockquote><p>ğŸ™‹<strong>Summary: For L2 normalized vectors, maximizing dot product is equivalent to maximizing cosine similarity is equivalent to minimizing Euclidean distance</strong></p></blockquote><h2 id="iii-how-hot-is-the-temperature" tabindex="-1">III. How Hot is the Temperature? <a class="header-anchor" href="#iii-how-hot-is-the-temperature" aria-label="Permalink to â€œIII. How Hot is the Temperature?â€">â€‹</a></h2><blockquote><p>Before proceeding, please make sure you understand the operations in <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html" target="_blank" rel="noreferrer">torch.nn.CrossEntropyLoss</a> (LogSoftmax + NLLLoss). This is crucial for understanding the source code.</p></blockquote><p>Consider a scenario: Using List-wise training with 1 positive sample and 3 negative samples, with cosine similarity as the training metric.</p><p>Suppose our model perfectly predicts a training sample, outputting logits (1, -1, -1, -1). Theoretically, the Loss should be 0, or at least very small. However, with CrossEntropyLoss, we get:</p><p>$$ -log(exp(1)/(exp(1)+exp(-1)*3))=0.341 $$</p><p>But if we divide the logits by a temperature coefficient $temperature=0.2$, making them (5, -5, -5, -5), after CrossEntropyLoss, we get:</p><p>$$ -log(exp(5)/(exp(5)+exp(-5)*3))=0.016 $$</p><p>This gives us a negligibly small Loss.</p><p>In other words, <strong>dividing logits by a temperature expands the upper and lower bounds of each element in the logits, bringing them back into the sensitive range of softmax operations</strong>.</p><p>In practice, L2 Norm is commonly used together with temperature scaling.</p></div></div></main><footer class="VPDocFooter" data-v-7011f0d8 data-v-e257564d><!--[--><!--]--><!----><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><!----></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/torch-rechub/blog/rank.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>Next page</span><span class="title" data-v-e257564d>Ranking Training Guide</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"blog_hllm_reproduction.md\":\"4v4-ONAu\",\"blog_match.md\":\"D2h5Vg4w\",\"blog_rank.md\":\"lldSgl7A\",\"contributing.md\":\"BAQUP8ng\",\"index.md\":\"BUpypesT\",\"introduction.md\":\"Da4YDT0v\",\"manual_api-reference_basic.md\":\"Dywq74dv\",\"manual_api-reference_models.md\":\"C3afZ6sP\",\"manual_api-reference_trainers.md\":\"CCrg5eIu\",\"manual_api-reference_utils.md\":\"BD9LmX_x\",\"manual_faq.md\":\"B11aVWMX\",\"manual_getting-started.md\":\"Bl-CEa8s\",\"manual_installation.md\":\"CcfoMTG5\",\"manual_tutorials_matching.md\":\"O2Ep1yWJ\",\"manual_tutorials_multi-task.md\":\"sub4Fubm\",\"manual_tutorials_ranking.md\":\"ePK_drO-\",\"zh_blog_hllm_reproduction.md\":\"D9L6lcri\",\"zh_blog_hstu_reproduction.md\":\"B6nDiEkP\",\"zh_blog_match.md\":\"DBamEsSq\",\"zh_blog_rank.md\":\"Cm5sDPTH\",\"zh_contributing.md\":\"_W9QQAB0\",\"zh_index.md\":\"DqyM1Xjc\",\"zh_introduction.md\":\"BhBianXM\",\"zh_manual_api-reference_basic.md\":\"CdZ0gnz6\",\"zh_manual_api-reference_models.md\":\"Ck_1OZhu\",\"zh_manual_api-reference_trainers.md\":\"CSLFG1Ck\",\"zh_manual_api-reference_utils.md\":\"CmbYK7lt\",\"zh_manual_faq.md\":\"DN9oVozv\",\"zh_manual_getting-started.md\":\"C-vY2RpE\",\"zh_manual_installation.md\":\"GnMznAj8\",\"zh_manual_tutorials_matching.md\":\"CMmUNOtS\",\"zh_manual_tutorials_multi-task.md\":\"jQbkObGC\",\"zh_manual_tutorials_ranking.md\":\"Brf6e-u7\",\"zh_å‚è€ƒèµ„æ–™_å‚è€ƒèµ„æ–™.md\":\"CWyLtMQf\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"torch-rechub\",\"description\":\"A Lighting Pytorch Framework for Recommendation Models, Easy-to-use and Easy-to-extend.\",\"base\":\"/torch-rechub/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"logo\":\"/img/logo.png\"},\"locales\":{\"root\":{\"label\":\"English\",\"lang\":\"en\",\"title\":\"torch-rechub\",\"description\":\"A Lighting Pytorch Framework for Recommendation Models, Easy-to-use and Easy-to-extend.\",\"themeConfig\":{\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Introduction\",\"link\":\"/introduction\"},{\"text\":\"Documentation\",\"link\":\"/manual/installation\"},{\"text\":\"API\",\"link\":\"/manual/api-reference/basic\"},{\"text\":\"Blog\",\"link\":\"/blog/match\"},{\"text\":\"Contributing\",\"link\":\"/contributing\"}],\"sidebar\":{\"/manual/\":[{\"text\":\"Getting Started\",\"items\":[{\"text\":\"Installation\",\"link\":\"/manual/installation\"},{\"text\":\"Getting Started\",\"link\":\"/manual/getting-started\"}]},{\"text\":\"Tutorials\",\"items\":[{\"text\":\"Recall Models\",\"link\":\"/manual/tutorials/matching\"},{\"text\":\"Ranking Models\",\"link\":\"/manual/tutorials/ranking\"},{\"text\":\"Multi-Task Learning\",\"link\":\"/manual/tutorials/multi-task\"}]},{\"text\":\"API Reference\",\"items\":[{\"text\":\"Basic Components\",\"link\":\"/manual/api-reference/basic\"},{\"text\":\"Models\",\"link\":\"/manual/api-reference/models\"},{\"text\":\"Trainers\",\"link\":\"/manual/api-reference/trainers\"},{\"text\":\"Utilities\",\"link\":\"/manual/api-reference/utils\"}]},{\"text\":\"Others\",\"items\":[{\"text\":\"FAQ\",\"link\":\"/manual/faq\"}]}],\"/blog/\":[{\"text\":\"Blog\",\"items\":[{\"text\":\"Matching Training Guide\",\"link\":\"/blog/match\"},{\"text\":\"Ranking Training Guide\",\"link\":\"/blog/rank\"},{\"text\":\"HSTU Reproduction\",\"link\":\"/blog/hstu_reproduction\"},{\"text\":\"HLLM Reproduction\",\"link\":\"/blog/hllm_reproduction\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/datawhalechina/torch-rechub\"}]}},\"zh\":{\"label\":\"ä¸­æ–‡\",\"lang\":\"zh-CN\",\"title\":\"torch-rechub\",\"description\":\"ä¸€ä¸ªåŸºäº PyTorch çš„æ˜“ç”¨ã€å¯æ‰©å±•ä¸”é«˜æ€§èƒ½çš„æ¨èç³»ç»Ÿæ¡†æ¶\",\"themeConfig\":{\"nav\":[{\"text\":\"é¦–é¡µ\",\"link\":\"/zh/\"},{\"text\":\"é¡¹ç›®ä»‹ç»\",\"link\":\"/zh/introduction\"},{\"text\":\"é¡¹ç›®æ–‡æ¡£\",\"link\":\"/zh/manual/installation\"},{\"text\":\"API\",\"link\":\"/zh/manual/api-reference/basic\"},{\"text\":\"åšå®¢\",\"link\":\"/zh/blog/match\"},{\"text\":\"è´¡çŒ®æŒ‡å—\",\"link\":\"/zh/contributing\"}],\"sidebar\":{\"/zh/manual/\":[{\"text\":\"å…¥é—¨æŒ‡å—\",\"items\":[{\"text\":\"å®‰è£…æŒ‡å—\",\"link\":\"/zh/manual/installation\"},{\"text\":\"å¿«é€Ÿå¼€å§‹\",\"link\":\"/zh/manual/getting-started\"}]},{\"text\":\"æ•™ç¨‹\",\"items\":[{\"text\":\"å¬å›æ¨¡å‹\",\"link\":\"/zh/manual/tutorials/matching\"},{\"text\":\"æ’åºæ¨¡å‹\",\"link\":\"/zh/manual/tutorials/ranking\"},{\"text\":\"å¤šä»»åŠ¡å­¦ä¹ \",\"link\":\"/zh/manual/tutorials/multi-task\"}]},{\"text\":\"API å‚è€ƒ\",\"items\":[{\"text\":\"åŸºç¡€ç»„ä»¶\",\"link\":\"/zh/manual/api-reference/basic\"},{\"text\":\"æ¨¡å‹\",\"link\":\"/zh/manual/api-reference/models\"},{\"text\":\"è®­ç»ƒå™¨\",\"link\":\"/zh/manual/api-reference/trainers\"},{\"text\":\"å·¥å…·ç±»\",\"link\":\"/zh/manual/api-reference/utils\"}]},{\"text\":\"å…¶ä»–\",\"items\":[{\"text\":\"å¸¸è§é—®é¢˜\",\"link\":\"/zh/manual/faq\"},{\"text\":\"å‚è€ƒèµ„æ–™\",\"link\":\"/zh/å‚è€ƒèµ„æ–™/å‚è€ƒèµ„æ–™\"}]}],\"/zh/blog/\":[{\"text\":\"åšå®¢\",\"items\":[{\"text\":\"å¬å›æ¨¡å‹è®­ç»ƒæŒ‡å—\",\"link\":\"/zh/blog/match\"},{\"text\":\"æ’åºæ¨¡å‹è®­ç»ƒæŒ‡å—\",\"link\":\"/zh/blog/rank\"},{\"text\":\"HSTU æ¨¡å‹å¤ç°\",\"link\":\"/zh/blog/hstu_reproduction\"},{\"text\":\"HLLM æ¨¡å‹å¤ç°\",\"link\":\"/zh/blog/hllm_reproduction\"}]}]},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/datawhalechina/torch-rechub\"}]}}},\"scrollOffset\":134,\"cleanUrls\":false,\"additionalConfig\":{}}");</script>
    
  </body>
</html>