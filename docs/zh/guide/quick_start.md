---
title: å¿«é€Ÿå¼€å§‹
description: Torch-RecHub å¿«é€Ÿå…¥é—¨æŒ‡å—ï¼Œ5åˆ†é’Ÿè·‘é€šç¬¬ä¸€ä¸ªæ¨èæ¨¡å‹
---

# å¿«é€Ÿå¼€å§‹

æœ¬æ•™ç¨‹å°†å¸®åŠ©ä½ åœ¨ **5 åˆ†é’Ÿå†…** è·‘é€šä¸€ä¸ªå®Œæ•´çš„æ¨èæ¨¡å‹è®­ç»ƒæµç¨‹ã€‚

## å®‰è£…

```bash
pip install torch-rechub
```

> ğŸ’¡ å»ºè®®åŒæ—¶å®‰è£…å¯é€‰ä¾èµ–ä»¥è·å¾—å®Œæ•´åŠŸèƒ½ï¼š
> ```bash
> pip install torch-rechub[all]  # åŒ…å« ONNX å¯¼å‡ºã€å®éªŒè¿½è¸ªç­‰åŠŸèƒ½
> ```

---

## ç¤ºä¾‹ 1ï¼šCTR é¢„æµ‹ï¼ˆç²¾æ’æ¨¡å‹ï¼‰

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¯ç›´æ¥è¿è¡Œçš„ DeepFM æ¨¡å‹è®­ç»ƒç¤ºä¾‹ï¼š

```python
import pandas as pd
import torch
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

from torch_rechub.basic.features import DenseFeature, SparseFeature
from torch_rechub.models.ranking import DeepFM
from torch_rechub.trainers import CTRTrainer
from torch_rechub.utils.data import DataGenerator

# ========== 1. å‡†å¤‡æ•°æ® ==========
# ä½¿ç”¨å†…ç½®çš„ Criteo æ ·æœ¬æ•°æ®ï¼ˆ100æ¡è®°å½•ï¼Œç”¨äºæ¼”ç¤ºï¼‰
# å®Œæ•´æ•°æ®ä¸‹è½½ï¼šhttps://www.kaggle.com/c/criteo-display-ad-challenge
data_url = "https://raw.githubusercontent.com/datawhalechina/torch-rechub/main/examples/ranking/data/criteo/criteo_sample.csv"
data = pd.read_csv(data_url)
print(f"æ•°æ®é›†å¤§å°: {len(data)} æ¡è®°å½•")

# ========== 2. ç‰¹å¾å¤„ç† ==========
# Criteo æ•°æ®é›†åŒ…å« 13 ä¸ªæ•°å€¼ç‰¹å¾ (I1-I13) å’Œ 26 ä¸ªç±»åˆ«ç‰¹å¾ (C1-C26)
dense_features = [f"I{i}" for i in range(1, 14)]
sparse_features = [f"C{i}" for i in range(1, 27)]

# å¡«å……ç¼ºå¤±å€¼
data[sparse_features] = data[sparse_features].fillna("-996")
data[dense_features] = data[dense_features].fillna(0)

# æ•°å€¼ç‰¹å¾å½’ä¸€åŒ–
scaler = MinMaxScaler()
data[dense_features] = scaler.fit_transform(data[dense_features])

# ç±»åˆ«ç‰¹å¾ç¼–ç 
for feat in sparse_features:
    encoder = LabelEncoder()
    data[feat] = encoder.fit_transform(data[feat].astype(str))

# ========== 3. å®šä¹‰ç‰¹å¾ç±»å‹ ==========
dense_feas = [DenseFeature(name) for name in dense_features]
sparse_feas = [
    SparseFeature(name, vocab_size=data[name].nunique(), embed_dim=16)
    for name in sparse_features
]

# ========== 4. åˆ›å»º DataLoader ==========
x = data.drop(columns=["label"])
y = data["label"]

dg = DataGenerator(x, y)
train_dl, val_dl, test_dl = dg.generate_dataloader(
    split_ratio=[0.7, 0.1],
    batch_size=256
)

# ========== 5. å®šä¹‰æ¨¡å‹ ==========
model = DeepFM(
    deep_features=dense_feas + sparse_feas,
    fm_features=sparse_feas,
    mlp_params={"dims": [256, 128], "dropout": 0.2, "activation": "relu"}
)

# ========== 6. è®­ç»ƒæ¨¡å‹ ==========
trainer = CTRTrainer(
    model,
    optimizer_params={"lr": 1e-3, "weight_decay": 1e-5},
    n_epoch=5,
    device="cpu",  # ä½¿ç”¨ GPU: "cuda:0"
)

trainer.fit(train_dl, val_dl)

# ========== 7. è¯„ä¼°æ¨¡å‹ ==========
auc = trainer.evaluate(model, test_dl)
print(f"æµ‹è¯•é›† AUC: {auc:.4f}")
```

**é¢„æœŸè¾“å‡ºï¼š**

```
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.47it/s]
validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 333.15it/s]
epoch: 0 validation: auc: 0.3666666666666667
epoch: 1
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 111.11it/s]
validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 399.08it/s]
epoch: 1 validation: auc: 0.3666666666666667
epoch: 2
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 95.60it/s]
validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 492.75it/s]
epoch: 2 validation: auc: 0.33333333333333337
epoch: 3
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 90.90it/s]
validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 499.20it/s]
epoch: 3 validation: auc: 0.3
epoch: 4
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 79.91it/s]
validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 500.27it/s]
epoch: 4 validation: auc: 0.3333333333333333
validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 249.71it/s]æµ‹è¯•é›† AUC: 0.9545
```

---

## ç¤ºä¾‹ 2ï¼šå¬å›æ¨¡å‹ï¼ˆåŒå¡” DSSMï¼‰

è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å¯ç›´æ¥è¿è¡Œçš„ DSSM åŒå¡”æ¨¡å‹è®­ç»ƒç¤ºä¾‹ï¼š

```python
import pandas as pd
import numpy as np
import torch
from sklearn.preprocessing import LabelEncoder

from torch_rechub.basic.features import SparseFeature, SequenceFeature
from torch_rechub.models.matching import DSSM
from torch_rechub.trainers import MatchTrainer
from torch_rechub.utils.data import df_to_dict, MatchDataGenerator
from torch_rechub.utils.match import generate_seq_feature_match, gen_model_input

torch.manual_seed(2022)

# ========== 1. å‡†å¤‡æ•°æ® ==========
# ä½¿ç”¨å†…ç½®çš„ MovieLens æ ·æœ¬æ•°æ®
data_url = "https://raw.githubusercontent.com/datawhalechina/torch-rechub/main/examples/matching/data/ml-1m/ml-1m_sample.csv"
data = pd.read_csv(data_url)
print(f"æ•°æ®é›†å¤§å°: {len(data)} æ¡è®°å½•")

# å¤„ç† genres ç‰¹å¾
data["cate_id"] = data["genres"].apply(lambda x: x.split("|")[0])

# ========== 2. ç‰¹å¾ç¼–ç  ==========
user_col, item_col = "user_id", "movie_id"
sparse_features = ["user_id", "movie_id", "gender", "age", "occupation", "zip", "cate_id"]

feature_max_idx = {}
for feat in sparse_features:
    encoder = LabelEncoder()
    data[feat] = encoder.fit_transform(data[feat]) + 1  # +1 ä¸º padding é¢„ç•™ 0
    feature_max_idx[feat] = data[feat].max() + 1

# ========== 3. å®šä¹‰ç”¨æˆ·å¡”å’Œç‰©å“å¡”ç‰¹å¾ ==========
user_cols = ["user_id", "gender", "age", "occupation", "zip"]
item_cols = ["movie_id", "cate_id"]

user_profile = data[user_cols].drop_duplicates("user_id")
item_profile = data[item_cols].drop_duplicates("movie_id")

# ========== 4. ç”Ÿæˆåºåˆ—ç‰¹å¾å’Œè®­ç»ƒæ•°æ® ==========
df_train, df_test = generate_seq_feature_match(
    data,
    user_col,
    item_col,
    time_col="timestamp",
    item_attribute_cols=[],
    sample_method=1,
    mode=0,  # point-wise
    neg_ratio=3,
    min_item=0
)

x_train = gen_model_input(df_train, user_profile, user_col, item_profile, item_col, seq_max_len=50)
y_train = x_train["label"]
x_train = {k: v for k, v in x_train.items() if k != "label"}
x_test = gen_model_input(df_test, user_profile, user_col, item_profile, item_col, seq_max_len=50)

# ========== 5. å®šä¹‰ç‰¹å¾ç±»å‹ ==========
user_features = [
    SparseFeature(name, vocab_size=feature_max_idx[name], embed_dim=16)
    for name in user_cols
]
user_features += [
    SequenceFeature(
        "hist_movie_id",
        vocab_size=feature_max_idx["movie_id"],
        embed_dim=16,
        pooling="mean",
        shared_with="movie_id"
    )
]

item_features = [
    SparseFeature(name, vocab_size=feature_max_idx[name], embed_dim=16)
    for name in item_cols
]

# ========== 6. åˆ›å»º DataLoader ==========
all_item = df_to_dict(item_profile)
test_user = x_test

dg = MatchDataGenerator(x=x_train, y=y_train)
train_dl, test_dl, item_dl = dg.generate_dataloader(test_user, all_item, batch_size=256)

# ========== 7. å®šä¹‰æ¨¡å‹ ==========
model = DSSM(
    user_features,
    item_features,
    temperature=0.02,
    user_params={"dims": [128, 64], "activation": "prelu"},
    item_params={"dims": [128, 64], "activation": "prelu"},
)

# ========== 8. è®­ç»ƒæ¨¡å‹ ==========
trainer = MatchTrainer(
    model,
    mode=0,  # point-wise
    optimizer_params={"lr": 1e-4, "weight_decay": 1e-6},
    n_epoch=2,
    device="cpu",
    model_path="./",
)

trainer.fit(train_dl)

# ========== 9. å¯¼å‡ºåµŒå…¥å‘é‡ ==========
user_embedding = trainer.inference_embedding(model, mode="user", data_loader=test_dl, model_path="./")
item_embedding = trainer.inference_embedding(model, mode="item", data_loader=item_dl, model_path="./")

print(f"ç”¨æˆ·åµŒå…¥ç»´åº¦: {user_embedding.shape}")
print(f"ç‰©å“åµŒå…¥ç»´åº¦: {item_embedding.shape}")
```

**é¢„æœŸè¾“å‡ºï¼š**

```
n_train: 384, n_test: 2
0 cold start user dropped 
epoch: 0
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.81s/it]
epoch: 1
train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.65s/it]
user inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.90s/it]
item inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:05<00:00,  5.23s/it]ç”¨æˆ·åµŒå…¥ç»´åº¦: torch.Size([2, 64])
ç‰©å“åµŒå…¥ç»´åº¦: torch.Size([93, 64])
```

---

## ä¸‹ä¸€æ­¥

ğŸ‰ æ­å–œï¼ä½ å·²ç»æˆåŠŸè¿è¡Œäº†ç¬¬ä¸€ä¸ªæ¨èæ¨¡å‹ã€‚æ¥ä¸‹æ¥å¯ä»¥ï¼š

- ğŸ“š æŸ¥çœ‹ [æ¨¡å‹æ–‡æ¡£](../models/intro.md) äº†è§£æ›´å¤šæ¨¡å‹ï¼ˆDCNã€MMOEã€YoutubeDNN ç­‰ï¼‰
- ğŸ”§ æŸ¥çœ‹ [å®Œæ•´ç¤ºä¾‹](https://github.com/datawhalechina/torch-rechub/tree/main/examples) äº†è§£æ›´å¤šæ•°æ®é›†å’Œè®­ç»ƒæŠ€å·§
- ğŸš€ æŸ¥çœ‹ [æ¨¡å‹éƒ¨ç½²](../serving/intro.md) äº†è§£å¦‚ä½•å¯¼å‡º ONNX å’Œæ„å»ºå‘é‡ç´¢å¼•
- ğŸ“Š æŸ¥çœ‹ [å®éªŒè¿½è¸ª](../tools/tracking.md) äº†è§£å¦‚ä½•ä½¿ç”¨ MLflow/TensorBoard è®°å½•å®éªŒ

---

## å¸¸è§é—®é¢˜

### Q: å¦‚ä½•ä½¿ç”¨ GPU è®­ç»ƒï¼Ÿ

å°† `device="cpu"` æ”¹ä¸º `device="cuda:0"`ï¼š

```python
trainer = CTRTrainer(model, device="cuda:0", ...)
```

### Q: å¦‚ä½•ä¿å­˜å’ŒåŠ è½½æ¨¡å‹ï¼Ÿ

```python
# ä¿å­˜
torch.save(model.state_dict(), "model.pth")

# åŠ è½½
model.load_state_dict(torch.load("model.pth"))
```

### Q: å¦‚ä½•å¯¼å‡º ONNX æ¨¡å‹ï¼Ÿ

```python
trainer.export_onnx("model.onnx")

# åŒå¡”æ¨¡å‹å¯åˆ†åˆ«å¯¼å‡º
trainer.export_onnx("user_tower.onnx", mode="user")
trainer.export_onnx("item_tower.onnx", mode="item")
```
