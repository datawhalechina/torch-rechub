# [Torch-RecHub] - Lightweight Recommender System Framework based on PyTorch

[![License](https://img.shields.io/badge/license-MIT-blue?style=for-the-badge)](LICENSE) 
![GitHub Repo stars](https://img.shields.io/github/stars/datawhalechina/torch-rechub?style=for-the-badge)
![GitHub forks](https://img.shields.io/github/forks/datawhalechina/torch-rechub?style=for-the-badge)
![GitHub issues](https://img.shields.io/github/issues/datawhalechina/torch-rechub?style=for-the-badge)
[![Python Version](https://img.shields.io/badge/python-3.8%2B-orange?style=for-the-badge)](https://www.python.org/) 
[![PyTorch Version](https://img.shields.io/badge/pytorch-1.7%2B-orange?style=for-the-badge)](https://pytorch.org/) 
[![annoy Version](https://img.shields.io/badge/annoy-1.17%2B-orange?style=for-the-badge)](https://pytorch.org/) 
[![pandas Version](https://img.shields.io/badge/pandas-1.2%2B-orange?style=for-the-badge)](https://pandas.pydata.org/) 
[![numpy Version](https://img.shields.io/badge/numpy-1.19%2B-orange?style=for-the-badge)](https://numpy.org/) 
[![scikit-learn Version](https://img.shields.io/badge/scikit_learn-0.23%2B-orange?style=for-the-badge)](https://scikit-learn.org/)
[![torch-rechub Version](https://img.shields.io/badge/torch_rechub-0.0.3%2B-orange?style=for-the-badge)](https://pypi.org/project/torch-rechub/)

English | [ç®€ä½“ä¸­æ–‡](README_zh.md)

**Torch-RecHub** is a flexible and extensible recommender system framework built with PyTorch. It aims to simplify research and application of recommendation algorithms by providing common model implementations, data processing tools, and evaluation metrics.

## âœ¨ Features

* **Modular Design:** Easy to add new models, datasets, and evaluation metrics.
* **PyTorch-based:** Leverages PyTorch's dynamic graph and GPU acceleration capabilities.
* **Rich Model Library:** Contains various classic and cutting-edge recommendation algorithms.
* **Standardized Pipeline:** Provides unified data loading, training, and evaluation workflows.
* **Easy Configuration:** Adjust experiment settings via config files or command-line arguments.
* **Reproducibility:** Designed to ensure reproducible experimental results.
* **Additional Features:** Negative sampling, multi-task learning, etc.

## ğŸ“– Table of Contents

- [\[Torch-RecHub\] - Lightweight Recommender System Framework based on PyTorch](#torch-rechub---lightweight-recommender-system-framework-based-on-pytorch)
  - [âœ¨ Features](#-features)
  - [ğŸ“– Table of Contents](#-table-of-contents)
  - [ğŸ”§ Installation](#-installation)
    - [Requirements](#requirements)
    - [Installation Steps](#installation-steps)
  - [ğŸš€ Quick Start](#-quick-start)
  - [ğŸ“‚ Project Structure](#-project-structure)
  - [ğŸ’¡ Supported Models](#-supported-models)
  - [ğŸ“Š Supported Datasets](#-supported-datasets)
  - [ğŸ§ª Examples](#-examples)
    - [Ranking (CTR Prediction)](#ranking-ctr-prediction)
    - [Multi-Task Ranking](#multi-task-ranking)
    - [Matching Model](#matching-model)
  - [ğŸ¤ Contributing](#-contributing)
  - [ğŸ“œ License](#-license)
  - [ğŸ“š Citation](#-citation)
  - [ğŸ“« Contact](#-contact)

## ğŸ”§ Installation

### Requirements

* Python 3.8+
* PyTorch 1.7+ (CUDA-enabled version recommended for GPU acceleration)
* NumPy
* Pandas
* SciPy
* Scikit-learn

### Installation Steps

**Stable Version (Recommended for Users):**
```bash
pip install torch-rechub
```

**Latest Version:**
```bash
# Install uv first (if not already installed)
pip install uv

# Clone and install
git clone https://github.com/datawhalechina/torch-rechub.git
cd torch-rechub
uv sync
```

## ğŸš€ Quick Start

Here's a simple example of training a model (e.g., DSSM) on the MovieLens dataset:

```bash
# Clone the repository (if using latest version)
git clone https://github.com/datawhalechina/torch-rechub.git
cd torch-rechub
uv sync

# Run example
python examples/matching/run_ml_dssm.py

# Or with custom parameters:
python examples/matching/run_ml_dssm.py --model_name dssm --device 'cuda:0' --learning_rate 0.001 --epoch 50 --batch_size 4096 --weight_decay 0.0001 --save_dir 'saved/dssm_ml-100k'
```

After training, model files will be saved in the `saved/dssm_ml-100k` directory (or your configured directory).

## ğŸ“‚ Project Structure

```
torch-rechub/             # Root directory
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ pyproject.toml        # Project configuration and dependencies
â”œâ”€â”€ torch_rechub/         # Core library
â”‚   â”œâ”€â”€ basic/            # Basic components
â”‚   â”‚   â”œâ”€â”€ activation.py # Activation functions
â”‚   â”‚   â”œâ”€â”€ features.py   # Feature engineering
â”‚   â”‚   â”œâ”€â”€ layers.py     # Neural network layers
â”‚   â”‚   â”œâ”€â”€ loss_func.py  # Loss functions
â”‚   â”‚   â””â”€â”€ metric.py     # Evaluation metrics
â”‚   â”œâ”€â”€ models/           # Recommendation model implementations
â”‚   â”‚   â”œâ”€â”€ matching/     # Matching models (DSSM/MIND/GRU4Rec etc.)
â”‚   â”‚   â”œâ”€â”€ ranking/      # Ranking models (WideDeep/DeepFM/DIN etc.)
â”‚   â”‚   â””â”€â”€ multi_task/   # Multi-task models (MMoE/ESMM etc.)
â”‚   â”œâ”€â”€ trainers/         # Training frameworks
â”‚   â”‚   â”œâ”€â”€ ctr_trainer.py    # CTR prediction trainer
â”‚   â”‚   â”œâ”€â”€ match_trainer.py  # Matching model trainer
â”‚   â”‚   â””â”€â”€ mtl_trainer.py    # Multi-task learning trainer
â”‚   â””â”€â”€ utils/            # Utility functions
â”‚       â”œâ”€â”€ data.py       # Data processing utilities
â”‚       â”œâ”€â”€ match.py      # Matching utilities
â”‚       â””â”€â”€ mtl.py        # Multi-task utilities
â”œâ”€â”€ examples/             # Example scripts
â”‚   â”œâ”€â”€ matching/         # Matching task examples
â”‚   â””â”€â”€ ranking/          # Ranking task examples
â”œâ”€â”€ docs/                 # Documentation
â”œâ”€â”€ tutorials/            # Jupyter tutorials
â”œâ”€â”€ tests/                # Unit tests
â”œâ”€â”€ config/               # Configuration files
â”œâ”€â”€ scripts/              # Utility scripts
â””â”€â”€ mkdocs.yml            # MkDocs config file
```

## ğŸ’¡ Supported Models

The framework currently supports the following recommendation models:

**General Recommendation:**

* **[DSSM](https://posenhuang.github.io/papers/cikm2013_DSSM_fullversion.pdf):** Deep Structured Semantic Model
* **[Wide&Deep](https://arxiv.org/abs/1606.07792):** Wide & Deep Learning for Recommender Systems
* **[FM](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf):** Factorization Machines
* **[DeepFM](https://arxiv.org/abs/1703.04247):** Deep Factorization Machine
* ... 

**Sequential Recommendation:**

* **[DIN](https://arxiv.org/pdf/1706.06978.pdf):** Deep Interest Network
* **[DIEN](https://arxiv.org/pdf/1809.03672.pdf):** Deep Interest Evolution Network
* **[BST](https://arxiv.org/pdf/1905.06874.pdf):** Behavior Sequence Transformer
* **[GRU4Rec](https://arxiv.org/pdf/1511.06939.pdf):** Gated Recurrent Unit for Recommendation
* **[SASRec](https://arxiv.org/pdf/1808.09781.pdf):** Self-Attentive Sequential Recommendation
* ... 

**Multi-Interest Recommendation:**

* **[MIND](https://arxiv.org/pdf/1904.08030.pdf):** Multi-Interest Network with Dynamic Routing
* **[SINE](https://arxiv.org/pdf/2103.06920.pdf):** Self-Interested Network for Recommendation
* ... 

**Multi-Task Recommendation:**

* **[ESMM](https://arxiv.org/pdf/1804.07931.pdf):** Entire Space Multi-Task Model
* **[MMoE](https://dl.acm.org/doi/pdf/10.1145/3219819.3220007):** Multi-Task Multi-Interest Network for Recommendation
* **[PLE](https://dl.acm.org/doi/pdf/10.1145/3394486.3403394):** Personalized Learning to Rank
* **[AITM](https://arxiv.org/pdf/2005.02553.pdf):** Adaptive Interest-Task Matching
* ... 

## ğŸ“Š Supported Datasets

The framework provides built-in support or preprocessing scripts for the following common datasets:

* **MovieLens**
* **Amazon**
* **Criteo**
* **Avazu** 
* **Census-Income**
* **BookCrossing**
* **Ali-ccp**
* **Yidian**
* ...

The expected data format is typically an interaction file containing:
- User ID
- Item ID 
- Rating (optional)
- Timestamp (optional)

For specific format requirements, please refer to the example code in the `tutorials` directory.

You can easily integrate your own datasets by ensuring they conform to the framework's data format requirements or by writing custom data loaders.


## ğŸ§ª Examples

All model usage examples can be found in `/examples`

### Ranking (CTR Prediction)

```python
from torch_rechub.models.ranking import DeepFM
from torch_rechub.trainers import CTRTrainer
from torch_rechub.utils.data import DataGenerator

dg = DataGenerator(x, y)
train_dataloader, val_dataloader, test_dataloader = dg.generate_dataloader(split_ratio=[0.7, 0.1], batch_size=256)

model = DeepFM(deep_features=deep_features, fm_features=fm_features, mlp_params={"dims": [256, 128], "dropout": 0.2, "activation": "relu"})

ctr_trainer = CTRTrainer(model)
ctr_trainer.fit(train_dataloader, val_dataloader)
auc = ctr_trainer.evaluate(ctr_trainer.model, test_dataloader)
```

### Multi-Task Ranking

```python
from torch_rechub.models.multi_task import SharedBottom, ESMM, MMOE, PLE, AITM
from torch_rechub.trainers import MTLTrainer

task_types = ["classification", "classification"] 
model = MMOE(features, task_types, 8, expert_params={"dims": [32,16]}, tower_params_list=[{"dims": [32, 16]}, {"dims": [32, 16]}])

mtl_trainer = MTLTrainer(model)
mtl_trainer.fit(train_dataloader, val_dataloader)
auc = ctr_trainer.evaluate(ctr_trainer.model, test_dataloader)
```

### Matching Model

```python
from torch_rechub.models.matching import DSSM
from torch_rechub.trainers import MatchTrainer
from torch_rechub.utils.data import MatchDataGenerator

dg = MatchDataGenerator(x y)
train_dl, test_dl, item_dl = dg.generate_dataloader(test_user, all_item, batch_size=256)

model = DSSM(user_features, item_features, temperature=0.02,
             user_params={
                 "dims": [256, 128, 64],
                 "activation": 'prelu',  
             },
             item_params={
                 "dims": [256, 128, 64],
                 "activation": 'prelu', 
             })

match_trainer = MatchTrainer(model)
match_trainer.fit(train_dl)
```

## ğŸ‘¨â€ğŸ’»â€ Contributors

Thanks to all contributors!

![GitHub contributors](https://img.shields.io/github/contributors/datawhalechina/torch-rechub?color=32A9C3&labelColor=1B3C4A&logo=contributorcovenant)

[![contributors](https://contrib.rocks/image?repo=datawhalechina/torch-rechub)](https://github.com/datawhalechina/torch-rechub/graphs/contributors)

## ğŸ¤ Contributing

We welcome contributions in all forms! Please refer to [CONTRIBUTING.md](CONTRIBUTING.md) for detailed contribution guidelines.

We also welcome bug reports and feature suggestions through [Issues](https://github.com/datawhalechina/torch-rechub/issues).

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

## ğŸ“š Citation

If you use this framework in your research or work, please consider citing:

```bibtex
@misc{torch_rechub,
    title = {Torch-RecHub},
    author = {Datawhale},
    year = {2024},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/datawhalechina/torch-rechub}},
    note = {A PyTorch-based recommender system framework providing easy-to-use and extensible solutions}
}
```

## ğŸ“« Contact

* **Project Lead:** [morningsky](https://github.com/morningsky) 
* [**GitHub Issues**](https://github.com/datawhalechina/torch-rechub/issues)


---

*Last updated: [2025-06-30]*