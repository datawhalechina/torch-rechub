{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "680cd405",
      "metadata": {},
      "source": [
        "# 04 实验跟踪（轻量）：model_logger 接入演示\n",
        "\n",
        "- **目标**：统一演示如何给 Trainer 传入 `model_logger` 来记录指标/超参。\n",
        "- **默认**：`model_logger=None`（不记录、不要求安装任何 tracking 依赖）。\n",
        "\n",
        "## 可选依赖\n",
        "- Wandb：`pip install wandb`\n",
        "- SwanLab：`pip install swanlab`\n",
        "- TensorBoardX：`pip install tensorboardX`（查看：`tensorboard --logdir ./runs`）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf22488",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['WANDB_API_KEY'] = \"your API_KEY\"\n",
        "# os.environ['SWANLAB_API_KEY'] = \"your API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bfa4b527",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATASET_PATH: e:\\RecommendSystemProject\\torch-rechub\\examples\\ranking\\data\\criteo\\criteo_sample.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_rechub.basic.features import DenseFeature, SparseFeature\n",
        "from torch_rechub.models.ranking import DeepFM\n",
        "from torch_rechub.trainers import CTRTrainer\n",
        "from torch_rechub.utils.data import DataGenerator\n",
        "\n",
        "# 跟踪组件（按需导入，未安装时会 ImportError）\n",
        "from torch_rechub.basic.tracking import WandbLogger, SwanLabLogger, TensorBoardXLogger\n",
        "\n",
        "SEED = 2022\n",
        "DEVICE = \"cpu\"\n",
        "DATASET_PATH = \"../examples/ranking/data/criteo/criteo_sample.csv\"\n",
        "\n",
        "EPOCH = 1\n",
        "BATCH_SIZE = 2048\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-3\n",
        "EARLYSTOP_PATIENCE = 2\n",
        "\n",
        "# 默认不启用任何 logger（保持轻量）\n",
        "USE_WANDB = False\n",
        "USE_SWANLAB = False\n",
        "USE_TENSORBOARD = False\n",
        "PROJECT_NAME = \"tracking-demo\"\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "print(\"DATASET_PATH:\", os.path.abspath(DATASET_PATH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "811cfa16",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_numeric_feature(val):\n",
        "    v = int(val)\n",
        "    if v > 2:\n",
        "        return int(np.log(v) ** 2)\n",
        "    else:\n",
        "        return v - 2\n",
        "\n",
        "\n",
        "def get_criteo_data_dict(data_path):\n",
        "    data = pd.read_csv(data_path, compression=\"gzip\") if data_path.endswith(\".gz\") else pd.read_csv(data_path)\n",
        "    dense_features = [f for f in data.columns.tolist() if f.startswith(\"I\")]\n",
        "    sparse_features = [f for f in data.columns.tolist() if f.startswith(\"C\")]\n",
        "\n",
        "    data[sparse_features] = data[sparse_features].fillna(\"0\")\n",
        "    data[dense_features] = data[dense_features].fillna(0)\n",
        "\n",
        "    for feat in tqdm(dense_features, desc=\"discretize dense\"):\n",
        "        sparse_features.append(feat + \"_cat\")\n",
        "        data[feat + \"_cat\"] = data[feat].apply(lambda x: convert_numeric_feature(x))\n",
        "\n",
        "    sca = MinMaxScaler()\n",
        "    data[dense_features] = sca.fit_transform(data[dense_features])\n",
        "\n",
        "    for feat in tqdm(sparse_features, desc=\"label encode sparse\"):\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "\n",
        "    dense_feas = [DenseFeature(name) for name in dense_features]\n",
        "    sparse_feas = [SparseFeature(name, vocab_size=data[name].nunique(), embed_dim=16) for name in sparse_features]\n",
        "\n",
        "    y = data[\"label\"]\n",
        "    x = data.drop(columns=[\"label\"])\n",
        "    return dense_feas, sparse_feas, x, y\n",
        "\n",
        "\n",
        "def build_loggers():\n",
        "    \"\"\"返回 list[BaseLogger] 或 None；未安装依赖时自动跳过。\"\"\"\n",
        "    loggers = []\n",
        "\n",
        "    if USE_WANDB:\n",
        "        try:\n",
        "            loggers.append(\n",
        "                WandbLogger(\n",
        "                    project=PROJECT_NAME,\n",
        "                    name=f\"deepfm-{SEED}\",\n",
        "                    config={\"lr\": LR, \"batch_size\": BATCH_SIZE, \"seed\": SEED},\n",
        "                    tags=[\"criteo\", \"ctr\", \"deepfm\"],\n",
        "                )\n",
        "            )\n",
        "            print(\"✓ WandbLogger initialized\")\n",
        "        except ImportError as e:\n",
        "            print(\"✗ Wandb not installed, skipped:\", e)\n",
        "\n",
        "    if USE_SWANLAB:\n",
        "        try:\n",
        "            loggers.append(\n",
        "                SwanLabLogger(\n",
        "                    project=PROJECT_NAME,\n",
        "                    experiment_name=f\"deepfm-{SEED}\",\n",
        "                    config={\"lr\": LR, \"batch_size\": BATCH_SIZE, \"seed\": SEED},\n",
        "                )\n",
        "            )\n",
        "            print(\"✓ SwanLabLogger initialized\")\n",
        "        except ImportError as e:\n",
        "            print(\"✗ SwanLab not installed, skipped:\", e)\n",
        "\n",
        "    if USE_TENSORBOARD:\n",
        "        try:\n",
        "            loggers.append(TensorBoardXLogger(log_dir=f\"./runs/deepfm-{SEED}\"))\n",
        "            print(\"✓ TensorBoardXLogger initialized: ./runs/deepfm-%s\" % SEED)\n",
        "        except ImportError as e:\n",
        "            print(\"✗ tensorboardX not installed, skipped:\", e)\n",
        "\n",
        "    return loggers if loggers else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "025966bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "discretize dense: 100%|██████████| 13/13 [00:00<00:00, 4332.96it/s]\n",
            "label encode sparse: 100%|██████████| 39/39 [00:00<00:00, 7790.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the samples of train : val : test are  80 : 11 : 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 1/1 [00:00<00:00, 24.02it/s]\n",
            "validation: 100%|██████████| 1/1 [00:00<00:00, 308.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0 validation: auc: 0.19999999999999998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "validation: 100%|██████████| 1/1 [00:00<00:00, 221.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test auc: 0.2875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dense_feas, sparse_feas, x, y = get_criteo_data_dict(DATASET_PATH)\n",
        "dg = DataGenerator(x, y)\n",
        "train_dl, val_dl, test_dl = dg.generate_dataloader(split_ratio=[0.7, 0.1], batch_size=BATCH_SIZE)\n",
        "\n",
        "model = DeepFM(\n",
        "    deep_features=dense_feas,\n",
        "    fm_features=sparse_feas,\n",
        "    mlp_params={\"dims\": [64, 32], \"dropout\": 0.1, \"activation\": \"relu\"},\n",
        ")\n",
        "\n",
        "model_logger = build_loggers()  # None 表示不记录\n",
        "\n",
        "# 也可以手动记录超参（Trainer 内部也会在合适时机调用 logger）\n",
        "if model_logger is not None:\n",
        "    for lg in model_logger:\n",
        "        lg.log_hyperparams({\"epoch\": EPOCH, \"lr\": LR, \"batch_size\": BATCH_SIZE, \"weight_decay\": WEIGHT_DECAY})\n",
        "\n",
        "ctr_trainer = CTRTrainer(\n",
        "    model,\n",
        "    optimizer_params={\"lr\": LR, \"weight_decay\": WEIGHT_DECAY},\n",
        "    n_epoch=EPOCH,\n",
        "    earlystop_patience=EARLYSTOP_PATIENCE,\n",
        "    device=DEVICE,\n",
        "    model_path=\"./\",\n",
        "    model_logger=model_logger,\n",
        ")\n",
        "\n",
        "ctr_trainer.fit(train_dl, val_dl)\n",
        "auc = ctr_trainer.evaluate(ctr_trainer.model, test_dl)\n",
        "print(f\"test auc: {auc}\")\n",
        "\n",
        "# 手动补充记录一个最终指标\n",
        "if model_logger is not None:\n",
        "    for lg in model_logger:\n",
        "        lg.log_metrics({\"test/auc\": float(auc)}, step=EPOCH)\n",
        "        lg.finish()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
