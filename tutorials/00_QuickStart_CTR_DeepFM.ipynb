{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cc25f1d0",
      "metadata": {},
      "source": [
        "# 00 QuickStart：CTR 预测（DeepFM）\n",
        "\n",
        "- **目标**：用最小示例跑通 CTR 训练流程：数据预处理（Dense/Sparse）→ 特征构造 → `CTRTrainer` 训练/验证/测试 **AUC**。\n",
        "- **数据**：Criteo sample（仓库内置）。\n",
        "- **默认**：不启用实验跟踪（`model_logger=None`），不导出 ONNX。\n",
        "\n",
        "## 环境\n",
        "- 必需：`torch`、`pandas`、`scikit-learn`\n",
        "- 可选（实验跟踪）：`wandb` / `swanlab` / `tensorboardX`\n",
        "- 可选（ONNX 导出/推理）：`onnx>=1.20.0`、`onnxruntime`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "62eafd42",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATASET_PATH: e:\\RecommendSystemProject\\torch-rechub\\examples\\ranking\\data\\criteo\\criteo_sample.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_rechub.basic.features import DenseFeature, SparseFeature\n",
        "from torch_rechub.models.ranking import DeepFM\n",
        "from torch_rechub.trainers import CTRTrainer\n",
        "from torch_rechub.utils.data import DataGenerator\n",
        "\n",
        "# 可选：实验跟踪（默认关闭）\n",
        "# from torch_rechub.basic.tracking import WandbLogger, SwanLabLogger, TensorBoardXLogger\n",
        "\n",
        "SEED = 2022\n",
        "DEVICE = \"cpu\"  # 可改为 \"cuda:0\"\n",
        "\n",
        "# 数据路径（相对 notebook 所在的 tutorials/ 目录）\n",
        "DATASET_PATH = \"../examples/ranking/data/criteo/criteo_sample.csv\"\n",
        "\n",
        "# 训练配置：尽量保持 5-10 分钟内可跑通\n",
        "EPOCH = 2\n",
        "BATCH_SIZE = 2048\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-3\n",
        "EARLYSTOP_PATIENCE = 4\n",
        "\n",
        "# 可选开关\n",
        "USE_TRACKING = False\n",
        "LOGGER_TYPE = None  # \"wandb\" | \"swanlab\" | \"tensorboard\" | None\n",
        "PROJECT_NAME = \"criteo-ctr\"\n",
        "EXPORT_ONNX = False\n",
        "ONNX_PATH = \"deepfm.onnx\"\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "print(\"DATASET_PATH:\", os.path.abspath(DATASET_PATH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "41707d6d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_numeric_feature(val: float | int) -> int:\n",
        "    \"\"\"与 examples/ranking/run_criteo.py 保持一致：把 dense 值离散化成一个新 sparse 特征。\"\"\"\n",
        "    v = int(val)\n",
        "    if v > 2:\n",
        "        return int(np.log(v) ** 2)\n",
        "    else:\n",
        "        return v - 2\n",
        "\n",
        "\n",
        "def get_criteo_data_dict(data_path: str):\n",
        "    \"\"\"复用并对齐仓库现有 Criteo 预处理风格。\"\"\"\n",
        "    data = pd.read_csv(data_path, compression=\"gzip\") if data_path.endswith(\".gz\") else pd.read_csv(data_path)\n",
        "    print(\"data load finished, shape=\", data.shape)\n",
        "\n",
        "    dense_features = [f for f in data.columns.tolist() if f.startswith(\"I\")]\n",
        "    sparse_features = [f for f in data.columns.tolist() if f.startswith(\"C\")]\n",
        "\n",
        "    data[sparse_features] = data[sparse_features].fillna(\"0\")\n",
        "    data[dense_features] = data[dense_features].fillna(0)\n",
        "\n",
        "    # dense → dense(归一化) + dense_cat(离散化后作为 sparse)\n",
        "    for feat in tqdm(dense_features, desc=\"discretize dense\"):\n",
        "        sparse_features.append(feat + \"_cat\")\n",
        "        data[feat + \"_cat\"] = data[feat].apply(lambda x: convert_numeric_feature(x))\n",
        "\n",
        "    sca = MinMaxScaler()\n",
        "    data[dense_features] = sca.fit_transform(data[dense_features])\n",
        "\n",
        "    for feat in tqdm(sparse_features, desc=\"label encode sparse\"):\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "\n",
        "    dense_feas = [DenseFeature(feature_name) for feature_name in dense_features]\n",
        "    sparse_feas = [\n",
        "        SparseFeature(feature_name, vocab_size=data[feature_name].nunique(), embed_dim=16)\n",
        "        for feature_name in sparse_features\n",
        "    ]\n",
        "\n",
        "    y = data[\"label\"]\n",
        "    x = data.drop(columns=[\"label\"])\n",
        "    return dense_feas, sparse_feas, x, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "437eb3bc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data load finished, shape= (115, 40)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "discretize dense: 100%|██████████| 13/13 [00:00<00:00, 4045.55it/s]\n",
            "label encode sparse: 100%|██████████| 39/39 [00:00<00:00, 9743.16it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the samples of train : val : test are  80 : 11 : 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 1/1 [00:00<00:00, 11.15it/s]\n",
            "validation: 100%|██████████| 1/1 [00:00<00:00, 285.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0 validation: auc: 0.4666666666666667\n",
            "epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 1/1 [00:00<00:00, 84.24it/s]\n",
            "validation: 100%|██████████| 1/1 [00:00<00:00, 500.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 validation: auc: 0.4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "validation: 100%|██████████| 1/1 [00:00<00:00, 322.89it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test auc: 0.3375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "dense_feas, sparse_feas, x, y = get_criteo_data_dict(DATASET_PATH)\n",
        "\n",
        "dg = DataGenerator(x, y)\n",
        "train_dl, val_dl, test_dl = dg.generate_dataloader(split_ratio=[0.7, 0.1], batch_size=BATCH_SIZE)\n",
        "\n",
        "model = DeepFM(\n",
        "    deep_features=dense_feas,\n",
        "    fm_features=sparse_feas,\n",
        "    mlp_params={\"dims\": [256, 128], \"dropout\": 0.2, \"activation\": \"relu\"},\n",
        ")\n",
        "\n",
        "# 默认不启用 logger\n",
        "model_logger = None\n",
        "\n",
        "# 如需启用：把 USE_TRACKING=True 并设置 LOGGER_TYPE\n",
        "# if USE_TRACKING:\n",
        "#     loggers = []\n",
        "#     if LOGGER_TYPE == \"wandb\":\n",
        "#         loggers.append(WandbLogger(project=PROJECT_NAME, name=f\"deepfm-{SEED}\", config={\"lr\": LR, \"batch_size\": BATCH_SIZE, \"seed\": SEED}, tags=[\"criteo\", \"ctr\", \"deepfm\"]))\n",
        "#     elif LOGGER_TYPE == \"swanlab\":\n",
        "#         loggers.append(SwanLabLogger(project=PROJECT_NAME, experiment_name=f\"deepfm-{SEED}\", config={\"lr\": LR, \"batch_size\": BATCH_SIZE, \"seed\": SEED}))\n",
        "#     elif LOGGER_TYPE == \"tensorboard\":\n",
        "#         loggers.append(TensorBoardXLogger(log_dir=f\"./runs/deepfm-{SEED}\"))\n",
        "#     model_logger = loggers if loggers else None\n",
        "\n",
        "ctr_trainer = CTRTrainer(\n",
        "    model,\n",
        "    optimizer_params={\"lr\": LR, \"weight_decay\": WEIGHT_DECAY},\n",
        "    n_epoch=EPOCH,\n",
        "    earlystop_patience=EARLYSTOP_PATIENCE,\n",
        "    device=DEVICE,\n",
        "    model_path=\"./\",\n",
        "    model_logger=model_logger,\n",
        ")\n",
        "\n",
        "ctr_trainer.fit(train_dl, val_dl)\n",
        "auc = ctr_trainer.evaluate(ctr_trainer.model, test_dl)\n",
        "print(f\"test auc: {auc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6fec045e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可选：导出 ONNX（默认关闭）\n",
        "# 说明：需要 onnx>=1.20.0，且某些环境需要额外安装 onnxruntime 做推理验证。\n",
        "\n",
        "if EXPORT_ONNX:\n",
        "    try:\n",
        "        ctr_trainer.export_onnx(ONNX_PATH, verbose=False, device=DEVICE)\n",
        "        print(\"exported:\", ONNX_PATH)\n",
        "    except Exception as e:\n",
        "        print(\"ONNX export failed:\", repr(e))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
