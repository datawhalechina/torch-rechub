{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cea0ead2",
      "metadata": {},
      "source": [
        "# 05 模型导出与推理验证：ONNX（CTR + Matching）\n",
        "\n",
        "- **目标**：演示 Torch-RecHub 模型导出 ONNX（含 dynamic axes），并用 onnxruntime 做一次最小推理验证。\n",
        "\n",
        "## 依赖\n",
        "- 导出：`onnx>=1.20.0`\n",
        "- 推理验证：`onnxruntime`\n",
        "- 可选（量化）：`onnxruntime`（INT8 动态量化），`onnxconverter-common`（FP16 转换）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5008ae43",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXPORT_DIR: e:\\RecommendSystemProject\\torch-rechub\\tutorials\\onnx_exports\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch_rechub.basic.features import DenseFeature, SparseFeature, SequenceFeature\n",
        "from torch_rechub.models.ranking import DeepFM\n",
        "from torch_rechub.models.matching import DSSM\n",
        "from torch_rechub.trainers import CTRTrainer\n",
        "from torch_rechub.utils.data import DataGenerator\n",
        "from torch_rechub.utils.onnx_export import ONNXExporter\n",
        "from torch_rechub.utils.model_utils import generate_dummy_input_dict\n",
        "\n",
        "SEED = 2022\n",
        "DEVICE = \"cuda:0\"\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "EXPORT_DIR = \"./onnx_exports\"\n",
        "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "print(\"EXPORT_DIR:\", os.path.abspath(EXPORT_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7fcb12a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "discretize dense: 100%|██████████| 13/13 [00:00<00:00, 4804.47it/s]\n",
            "label encode sparse: 100%|██████████| 39/39 [00:00<00:00, 13004.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the samples of train : val : test are  80 : 11 : 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]\n",
            "validation: 100%|██████████| 1/1 [00:00<00:00, 24.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 0 validation: auc: 0.16666666666666666\n",
            "exported: ./onnx_exports\\deepfm.onnx\n"
          ]
        }
      ],
      "source": [
        "# ---------- Part A: CTR（DeepFM）导出 + onnxruntime 推理验证 ----------\n",
        "\n",
        "DATASET_PATH = \"../examples/ranking/data/criteo/criteo_sample.csv\"\n",
        "EPOCH = 1\n",
        "BATCH_SIZE = 2048\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-3\n",
        "\n",
        "\n",
        "def convert_numeric_feature(val):\n",
        "    v = int(val)\n",
        "    if v > 2:\n",
        "        return int(np.log(v) ** 2)\n",
        "    else:\n",
        "        return v - 2\n",
        "\n",
        "\n",
        "def get_criteo_data_dict(data_path):\n",
        "    data = pd.read_csv(data_path, compression=\"gzip\") if data_path.endswith(\".gz\") else pd.read_csv(data_path)\n",
        "    dense_features = [f for f in data.columns.tolist() if f.startswith(\"I\")]\n",
        "    sparse_features = [f for f in data.columns.tolist() if f.startswith(\"C\")]\n",
        "\n",
        "    data[sparse_features] = data[sparse_features].fillna(\"0\")\n",
        "    data[dense_features] = data[dense_features].fillna(0)\n",
        "\n",
        "    for feat in tqdm(dense_features, desc=\"discretize dense\"):\n",
        "        sparse_features.append(feat + \"_cat\")\n",
        "        data[feat + \"_cat\"] = data[feat].apply(lambda x: convert_numeric_feature(x))\n",
        "\n",
        "    sca = MinMaxScaler()\n",
        "    # MinMaxScaler 默认输出 float64，这会导致后续 dataloader/ONNX 输入变成 double。\n",
        "    # 这里显式转成 float32，保证与导出的 ONNX（通常期望 float32）一致。\n",
        "    data[dense_features] = sca.fit_transform(data[dense_features]).astype(np.float32)\n",
        "\n",
        "    for feat in tqdm(sparse_features, desc=\"label encode sparse\"):\n",
        "        lbe = LabelEncoder()\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "\n",
        "    dense_feas = [DenseFeature(name) for name in dense_features]\n",
        "    sparse_feas = [SparseFeature(name, vocab_size=data[name].nunique(), embed_dim=16) for name in sparse_features]\n",
        "\n",
        "    y = data[\"label\"]\n",
        "    x = data.drop(columns=[\"label\"])\n",
        "    return dense_feas, sparse_feas, x, y\n",
        "\n",
        "\n",
        "dense_feas, sparse_feas, x, y = get_criteo_data_dict(DATASET_PATH)\n",
        "dg = DataGenerator(x, y)\n",
        "train_dl, val_dl, test_dl = dg.generate_dataloader(split_ratio=[0.7, 0.1], batch_size=BATCH_SIZE)\n",
        "\n",
        "ctr_model = DeepFM(\n",
        "    deep_features=dense_feas,\n",
        "    fm_features=sparse_feas,\n",
        "    mlp_params={\"dims\": [64, 32], \"dropout\": 0.1, \"activation\": \"relu\"},\n",
        ")\n",
        "\n",
        "ctr_trainer = CTRTrainer(\n",
        "    ctr_model,\n",
        "    optimizer_params={\"lr\": LR, \"weight_decay\": WEIGHT_DECAY},\n",
        "    n_epoch=EPOCH,\n",
        "    earlystop_patience=2,\n",
        "    device=DEVICE,\n",
        "    model_path=\"./\",\n",
        ")\n",
        "ctr_trainer.fit(train_dl, val_dl)\n",
        "\n",
        "ctr_onnx_path = os.path.join(EXPORT_DIR, \"deepfm.onnx\")\n",
        "exporter = ONNXExporter(ctr_model, device=DEVICE)\n",
        "exporter.export(ctr_onnx_path, opset_version=14, dynamic_batch=True, verbose=False)\n",
        "print(\"exported:\", ctr_onnx_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f50f544",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch_out shape: (24,) onnx_out shape: (24,)\n",
            "max_abs_diff: 5.960464477539063e-08\n"
          ]
        }
      ],
      "source": [
        "# 用 onnxruntime 做一次最小推理验证（允许浮点误差）\n",
        "# 注意：如果你把 DEVICE 设为 cuda，需要把 batch 输入也搬到同一设备。\n",
        "\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "\n",
        "    # 取一个 batch（dataloader 默认产出 CPU tensors）\n",
        "    batch_x, _ = next(iter(test_dl))\n",
        "\n",
        "    ctr_model.eval()\n",
        "    model_device = next(ctr_model.parameters()).device\n",
        "\n",
        "    # torch 推理（把输入搬到模型所在 device）；同时把 double → float32\n",
        "    batch_x_torch = {\n",
        "        k: (v.float() if v.dtype == torch.float64 else v).to(model_device)\n",
        "        for k, v in batch_x.items()\n",
        "    }\n",
        "    with torch.no_grad():\n",
        "        torch_out = ctr_model(batch_x_torch).detach().cpu().numpy()\n",
        "\n",
        "    # ONNXRuntime 推理（输入需为 numpy，通常在 CPU 上即可）\n",
        "    # 注意：ONNX 常见期望 float32；这里对所有 float64 显式转 float32，并按 onnx 输入签名补齐维度。\n",
        "    ort_sess = ort.InferenceSession(ctr_onnx_path, providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "    # 根据 onnx 输入签名，修正 rank（常见：模型期望 (B,1)，而 dataloader 给的是 (B,)）\n",
        "    ort_inputs = {}\n",
        "    ort_input_info = {i.name: i for i in ort_sess.get_inputs()}\n",
        "    for k, v in batch_x.items():\n",
        "        if v.dtype == torch.float64:\n",
        "            v = v.float()\n",
        "        arr = v.detach().cpu().numpy()\n",
        "\n",
        "        info = ort_input_info.get(k)\n",
        "        if info is not None and hasattr(info, \"shape\"):\n",
        "            expected_rank = len(info.shape)\n",
        "            if expected_rank == 2 and arr.ndim == 1:\n",
        "                arr = arr.reshape(-1, 1)\n",
        "\n",
        "        ort_inputs[k] = arr\n",
        "\n",
        "    ort_out = ort_sess.run(None, ort_inputs)[0]\n",
        "\n",
        "    max_abs_diff = float(np.max(np.abs(torch_out - ort_out)))\n",
        "    print(\"torch_out shape:\", torch_out.shape, \"onnx_out shape:\", ort_out.shape)\n",
        "    print(\"max_abs_diff:\", max_abs_diff)\n",
        "except ImportError as e:\n",
        "    print(\"onnxruntime not installed, skip inference check:\", e)\n",
        "except Exception as e:\n",
        "    print(\"inference check failed:\", repr(e))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81db24d0",
      "metadata": {},
      "source": [
        "## 可选：ONNX 模型量化（INT8 / FP16）\n",
        "\n",
        "下面演示在已导出的 ONNX 模型基础上进行压缩：\n",
        "- **INT8 动态量化**：更偏向 CPU 推理加速（常见于 MLP/Linear）。\n",
        "- **FP16 转换**：更偏向 GPU 推理（降低显存占用）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a511d3da",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exported int8: ./onnx_exports\\deepfm.int8.onnx\n",
            "exported fp16: ./onnx_exports\\deepfm.fp16.onnx\n"
          ]
        }
      ],
      "source": [
        "# 量化/转换导出的 ONNX（可选）\n",
        "\n",
        "from torch_rechub.utils import quantize_model\n",
        "\n",
        "ctr_onnx_int8_path = os.path.join(EXPORT_DIR, \"deepfm.int8.onnx\")\n",
        "ctr_onnx_fp16_path = os.path.join(EXPORT_DIR, \"deepfm.fp16.onnx\")\n",
        "\n",
        "# INT8 动态量化（需要 onnxruntime）\n",
        "try:\n",
        "    quantize_model(ctr_onnx_path, ctr_onnx_int8_path, mode=\"int8\")\n",
        "    print(\"exported int8:\", ctr_onnx_int8_path)\n",
        "except Exception as e:\n",
        "    print(\"INT8 quantize skipped:\", repr(e))\n",
        "\n",
        "# FP16 转换（需要 onnx + onnxconverter-common）\n",
        "try:\n",
        "    quantize_model(ctr_onnx_path, ctr_onnx_fp16_path, mode=\"fp16\", keep_io_types=True)\n",
        "    print(\"exported fp16:\", ctr_onnx_fp16_path)\n",
        "except Exception as e:\n",
        "    print(\"FP16 convert skipped:\", repr(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "941134e0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exported: ./onnx_exports\\user_tower.onnx\n",
            "exported: ./onnx_exports\\item_tower.onnx\n"
          ]
        }
      ],
      "source": [
        "# ---------- Part B: Matching（DSSM）双塔导出 + 最小推理验证 ----------\n",
        "\n",
        "# 为了让本教程独立且快速，这里构造一个最小 DSSM 模型（不依赖完整训练），并导出 user/item tower。\n",
        "\n",
        "# user tower features\n",
        "user_features = [\n",
        "    SparseFeature(\"user_id\", vocab_size=1000, embed_dim=16),\n",
        "    SparseFeature(\"gender\", vocab_size=3, embed_dim=16),\n",
        "    SparseFeature(\"age\", vocab_size=10, embed_dim=16),\n",
        "    SparseFeature(\"occupation\", vocab_size=30, embed_dim=16),\n",
        "    SparseFeature(\"zip\", vocab_size=5000, embed_dim=16),\n",
        "    SequenceFeature(\"hist_movie_id\", vocab_size=5000, embed_dim=16, pooling=\"mean\", shared_with=\"movie_id\"),\n",
        "]\n",
        "\n",
        "# item tower features\n",
        "item_features = [\n",
        "    SparseFeature(\"movie_id\", vocab_size=5000, embed_dim=16),\n",
        "    SparseFeature(\"cate_id\", vocab_size=50, embed_dim=16),\n",
        "]\n",
        "\n",
        "match_model = DSSM(\n",
        "    user_features,\n",
        "    item_features,\n",
        "    temperature=0.02,\n",
        "    user_params={\"dims\": [64], \"activation\": \"prelu\"},\n",
        "    item_params={\"dims\": [64], \"activation\": \"prelu\"},\n",
        ")\n",
        "\n",
        "user_onnx_path = os.path.join(EXPORT_DIR, \"user_tower.onnx\")\n",
        "item_onnx_path = os.path.join(EXPORT_DIR, \"item_tower.onnx\")\n",
        "\n",
        "match_exporter = ONNXExporter(match_model, device=DEVICE)\n",
        "match_exporter.export(user_onnx_path, mode=\"user\", opset_version=14, dynamic_batch=True, verbose=False)\n",
        "match_exporter.export(item_onnx_path, mode=\"item\", opset_version=14, dynamic_batch=True, verbose=False)\n",
        "\n",
        "print(\"exported:\", user_onnx_path)\n",
        "print(\"exported:\", item_onnx_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7b267024",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user torch/onnx shapes: (2, 64) (2, 64)\n",
            "item torch/onnx shapes: (2, 64) (2, 64)\n",
            "user max_abs_diff: 5.960464477539063e-08\n",
            "item max_abs_diff: 5.960464477539063e-08\n"
          ]
        }
      ],
      "source": [
        "# 双塔最小推理验证：分别对 user/item tower 做一次 onnxruntime forward\n",
        "\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "\n",
        "    # 生成与 feature 定义一致的 dummy 输入\n",
        "    dummy_user = generate_dummy_input_dict(user_features, batch_size=2, seq_length=10, device=DEVICE)\n",
        "    dummy_item = generate_dummy_input_dict(item_features, batch_size=2, seq_length=10, device=DEVICE)\n",
        "\n",
        "    match_model.eval()\n",
        "    with torch.no_grad():\n",
        "        # user tower\n",
        "        match_model.mode = \"user\"\n",
        "        torch_user_out = match_model(dummy_user).detach().cpu().numpy()\n",
        "        # item tower\n",
        "        match_model.mode = \"item\"\n",
        "        torch_item_out = match_model(dummy_item).detach().cpu().numpy()\n",
        "\n",
        "    # onnxruntime\n",
        "    user_sess = ort.InferenceSession(user_onnx_path, providers=[\"CPUExecutionProvider\"])\n",
        "    item_sess = ort.InferenceSession(item_onnx_path, providers=[\"CPUExecutionProvider\"])\n",
        "\n",
        "    ort_user_in = {k: v.detach().cpu().numpy() for k, v in dummy_user.items()}\n",
        "    ort_item_in = {k: v.detach().cpu().numpy() for k, v in dummy_item.items()}\n",
        "\n",
        "    ort_user_out = user_sess.run(None, ort_user_in)[0]\n",
        "    ort_item_out = item_sess.run(None, ort_item_in)[0]\n",
        "\n",
        "    print(\"user torch/onnx shapes:\", torch_user_out.shape, ort_user_out.shape)\n",
        "    print(\"item torch/onnx shapes:\", torch_item_out.shape, ort_item_out.shape)\n",
        "\n",
        "    print(\"user max_abs_diff:\", float(np.max(np.abs(torch_user_out - ort_user_out))))\n",
        "    print(\"item max_abs_diff:\", float(np.max(np.abs(torch_item_out - ort_item_out))))\n",
        "except ImportError as e:\n",
        "    print(\"onnxruntime not installed, skip inference check:\", e)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
